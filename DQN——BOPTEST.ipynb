{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5580130b-9f8d-479f-978e-eec8b265b07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ“Œ DQN ä»£ç å·²åŠ è½½ (ä¿®å¤ç‰ˆ)\n",
      "åŠ¨ä½œç©ºé—´: 24\n",
      "è¿è¡Œ: train()\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "BOPTEST HVAC DQN è®­ç»ƒ - ä¿®å¤ç‰ˆï¼ˆç§»é™¤ä¸å¿…è¦çš„ select æ­¥éª¤ï¼‰\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =====================================================================\n",
    "# é…ç½®å‚æ•°\n",
    "# =====================================================================\n",
    "BOPTEST_URL = os.getenv(\"BOPTEST_URL\", \"http://localhost:80\")\n",
    "TESTCASE_NAME = \"bestest_air\"\n",
    "\n",
    "TOTAL_EPISODES = 500\n",
    "STEPS_PER_EPISODE = 96*2  # 2 days (96 steps = 1 day, 15min per step)\n",
    "EVAL_FREQUENCY = 20\n",
    "PLOT_SAVE_DIR = \"training_output\"\n",
    "DATA_SAVE_DIR = \"training_data\"  # æ•°æ®ä¿å­˜ç›®å½•\n",
    "\n",
    "# DQN è¶…å‚æ•°ï¼ˆä¼˜åŒ–ç‰ˆï¼‰\n",
    "GAMMA = 0.99\n",
    "LR = 3e-4  # æé«˜å­¦ä¹ ç‡ï¼ŒåŠ å¿«å­¦ä¹ \n",
    "BATCH_SIZE = 128  # å¢å¤§batch sizeï¼Œæ›´ç¨³å®š\n",
    "BUFFER_SIZE = 100_000  # å¢å¤§buffer\n",
    "MIN_REPLAY_SIZE = 2_000  # å¢åŠ æœ€å°æ ·æœ¬æ•°\n",
    "TARGET_UPDATE = 100  # æ›´é¢‘ç¹æ›´æ–°target network\n",
    "EPS_START = 1.0\n",
    "EPS_END = 0.1  # ä¿ç•™æ›´å¤šæ¢ç´¢\n",
    "EPS_DECAY_STEPS = 20_000  # å»¶é•¿æ¢ç´¢æœŸ\n",
    "TAU = 0.005  # æ›´å¹³æ»‘çš„è½¯æ›´æ–°\n",
    "\n",
    "# åŠ¨ä½œç©ºé—´\n",
    "FAN_LEVELS = [0.3, 0.6, 0.9]\n",
    "SUPPLY_TEMP_LEVELS = [288.15, 296.15]\n",
    "HEAT_SETPOINT_LEVELS = [294.15, 296.15]\n",
    "COOL_SETPOINT_LEVELS = [299.15, 301.15]\n",
    "\n",
    "NUM_ACTIONS = (\n",
    "    len(FAN_LEVELS)\n",
    "    * len(SUPPLY_TEMP_LEVELS)\n",
    "    * len(HEAT_SETPOINT_LEVELS)\n",
    "    * len(COOL_SETPOINT_LEVELS)\n",
    ")\n",
    "\n",
    "# =====================================================================\n",
    "# å·¥å…·å‡½æ•°\n",
    "# =====================================================================\n",
    "\n",
    "def log(msg, level=\"INFO\"):\n",
    "    ts = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(f\"[{ts}] {level:5s} | {msg}\", flush=True)\n",
    "\n",
    "\n",
    "def safe_json(resp, ctx=\"\"):\n",
    "    try:\n",
    "        return resp.json()\n",
    "    except Exception as e:\n",
    "        log(\n",
    "            f\"JSON è§£æå¤±è´¥({ctx}): {type(e).__name__}: {e}. status={resp.status_code}, text={resp.text[:300]}\",\n",
    "            \"ERROR\",\n",
    "        )\n",
    "        return None\n",
    "\n",
    "\n",
    "def K2C(k):\n",
    "    return k - 273.15\n",
    "\n",
    "\n",
    "def action_to_values(action_idx):\n",
    "    cool_idx = action_idx % len(COOL_SETPOINT_LEVELS)\n",
    "    remaining = action_idx // len(COOL_SETPOINT_LEVELS)\n",
    "    heat_idx = remaining % len(HEAT_SETPOINT_LEVELS)\n",
    "    remaining //= len(HEAT_SETPOINT_LEVELS)\n",
    "    supply_idx = remaining % len(SUPPLY_TEMP_LEVELS)\n",
    "    fan_idx = remaining // len(SUPPLY_TEMP_LEVELS)\n",
    "\n",
    "    v = {\n",
    "        \"fan\": FAN_LEVELS[fan_idx],\n",
    "        \"supply_temp\": SUPPLY_TEMP_LEVELS[supply_idx],\n",
    "        \"heat_setpoint\": HEAT_SETPOINT_LEVELS[heat_idx],\n",
    "        \"cool_setpoint\": COOL_SETPOINT_LEVELS[cool_idx],\n",
    "    }\n",
    "\n",
    "    if v[\"cool_setpoint\"] <= v[\"heat_setpoint\"] + 1.5:\n",
    "        v[\"cool_setpoint\"] = v[\"heat_setpoint\"] + 1.5\n",
    "\n",
    "    v[\"fan\"] = float(np.clip(v[\"fan\"], 0.0, 1.0))\n",
    "    v[\"supply_temp\"] = float(np.clip(v[\"supply_temp\"], 285.15, 313.15))\n",
    "    v[\"heat_setpoint\"] = float(np.clip(v[\"heat_setpoint\"], 278.15, 308.15))\n",
    "    v[\"cool_setpoint\"] = float(np.clip(v[\"cool_setpoint\"], 278.15, 308.15))\n",
    "    return v\n",
    "\n",
    "\n",
    "def action_to_string(action_idx):\n",
    "    v = action_to_values(action_idx)\n",
    "    return (\n",
    "        f\"Fan={v['fan']:.1f}|ä¾›é£={K2C(v['supply_temp']):.0f}Â°C|\"\n",
    "        f\"çƒ­è®¾={K2C(v['heat_setpoint']):.1f}Â°C|å†·è®¾={K2C(v['cool_setpoint']):.1f}Â°C\"\n",
    "    )\n",
    "\n",
    "# =====================================================================\n",
    "# ç¯å¢ƒå°è£…ï¼ˆä¿®å¤ç‰ˆ - ç›´æ¥ä½¿ç”¨ testcase åç§°ï¼‰\n",
    "# =====================================================================\n",
    "\n",
    "class BOPTESTEnv:\n",
    "    def __init__(self):\n",
    "        self.url = BOPTEST_URL\n",
    "        self.testid = None  # éœ€è¦é€šè¿‡ select è·å–\n",
    "        self.obs_dim = 12\n",
    "        self.action_dim = NUM_ACTIONS\n",
    "        self.prev_action_norm = 0.0\n",
    "\n",
    "    def _select_testcase(self):\n",
    "        \"\"\"é€‰æ‹©æµ‹è¯•æ¡ˆä¾‹ï¼Œè·å– testid\"\"\"\n",
    "        log(f\"é€‰æ‹©æµ‹è¯•æ¡ˆä¾‹: {TESTCASE_NAME}\")\n",
    "        max_retries = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                log(f\"å°è¯•é€‰æ‹©æµ‹è¯•æ¡ˆä¾‹ (å°è¯• {attempt + 1}/{max_retries})...\")\n",
    "                resp = requests.post(\n",
    "                    f\"{self.url}/testcases/{TESTCASE_NAME}/select\", \n",
    "                    timeout=120\n",
    "                )\n",
    "                if resp.status_code == 200:\n",
    "                    data = safe_json(resp, \"select testcase\")\n",
    "                    if data:\n",
    "                        self.testid = data.get('testid') or data.get('testcaseid')\n",
    "                        if self.testid:\n",
    "                            log(f\"âœ… Test ID: {self.testid}\")\n",
    "                            time.sleep(3)  # ç­‰å¾… worker åˆå§‹åŒ–\n",
    "                            return True\n",
    "                        else:\n",
    "                            log(\"âŒ æœªè¿”å› testid\", \"ERROR\")\n",
    "                else:\n",
    "                    log(\n",
    "                        f\"âŒ é€‰æ‹©å¤±è´¥ï¼ŒçŠ¶æ€ç ={resp.status_code}, å“åº”={resp.text[:200]}\",\n",
    "                        \"ERROR\",\n",
    "                    )\n",
    "            except requests.exceptions.Timeout:\n",
    "                log(f\"âŒ é€‰æ‹©è¶…æ—¶ (å°è¯• {attempt + 1}/{max_retries})\", \"WARN\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = 10 * (attempt + 1)\n",
    "                    log(f\"ç­‰å¾… {wait_time} ç§’åé‡è¯•...\")\n",
    "                    time.sleep(wait_time)\n",
    "            except Exception as e:\n",
    "                log(f\"âŒ é€‰æ‹©å¤±è´¥: {e} (å°è¯• {attempt + 1}/{max_retries})\", \"ERROR\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = 10 * (attempt + 1)\n",
    "                    log(f\"ç­‰å¾… {wait_time} ç§’åé‡è¯•...\")\n",
    "                    time.sleep(wait_time)\n",
    "        return False\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"é‡ç½®ç¯å¢ƒ\"\"\"\n",
    "        log(\"å¼€å§‹é‡ç½®ç¯å¢ƒ...\")\n",
    "        \n",
    "        # æ¯æ¬¡ reset éƒ½é‡æ–°é€‰æ‹©æµ‹è¯•æ¡ˆä¾‹ï¼ˆç¡®ä¿è·å–æ–°çš„ testidï¼‰\n",
    "        # å¦‚æœä¹‹å‰æœ‰ testidï¼Œå…ˆåœæ­¢å®ƒ\n",
    "        if self.testid:\n",
    "            try:\n",
    "                requests.put(f\"{self.url}/stop/{self.testid}\", timeout=10)\n",
    "                log(f\"å·²åœæ­¢ä¹‹å‰çš„ testid: {self.testid}\")\n",
    "            except:\n",
    "                pass\n",
    "            self.testid = None\n",
    "        \n",
    "        # é€‰æ‹©æµ‹è¯•æ¡ˆä¾‹ï¼Œè·å–æ–°çš„ testid\n",
    "        if not self._select_testcase():\n",
    "            raise Exception(\"æ— æ³•é€‰æ‹©æµ‹è¯•æ¡ˆä¾‹\")\n",
    "        \n",
    "        try:\n",
    "            # æ­¥éª¤1: åˆå§‹åŒ–\n",
    "            log(\"  â†’ Initialize...\")\n",
    "            resp = requests.put(\n",
    "                f\"{self.url}/initialize/{self.testid}\",\n",
    "                json={\"start_time\": 0, \"warmup_period\": 0},\n",
    "                timeout=120,\n",
    "            )\n",
    "            if resp.status_code != 200:\n",
    "                raise Exception(f\"Initialize å¤±è´¥: {resp.status_code}, {resp.text[:200]}\")\n",
    "            log(\"  âœ“ Initialize æˆåŠŸ\")\n",
    "            \n",
    "            # æ­¥éª¤2: è®¾ç½®æ­¥é•¿\n",
    "            log(\"  â†’ Set step...\")\n",
    "            resp = requests.put(\n",
    "                f\"{self.url}/step/{self.testid}\", \n",
    "                json={\"step\": 900}, \n",
    "                timeout=60,\n",
    "            )\n",
    "            if resp.status_code != 200:\n",
    "                raise Exception(f\"Set step å¤±è´¥: {resp.status_code}\")\n",
    "            log(\"  âœ“ Set step æˆåŠŸ\")\n",
    "            \n",
    "            # æ­¥éª¤3: ç¬¬ä¸€æ¬¡ advance\n",
    "            log(\"  â†’ Advance...\")\n",
    "            resp = requests.post(\n",
    "                f\"{self.url}/advance/{self.testid}\", \n",
    "                json={}, \n",
    "                timeout=60,\n",
    "            )\n",
    "            if resp.status_code != 200:\n",
    "                raise Exception(f\"Advance å¤±è´¥: {resp.status_code}\")\n",
    "            \n",
    "            payload = resp.json().get('payload', {})\n",
    "            self.prev_action_norm = 0.0\n",
    "            log(\"âœ… ç¯å¢ƒé‡ç½®æˆåŠŸ\")\n",
    "            return self._get_obs(payload)\n",
    "            \n",
    "        except Exception as e:\n",
    "            log(f\"âŒ é‡ç½®å¤±è´¥: {e}\", \"ERROR\")\n",
    "            raise\n",
    "\n",
    "    def step(self, action_idx):\n",
    "        action = action_to_values(action_idx)\n",
    "        control = {\n",
    "            'fcu_oveFan_u': action['fan'],\n",
    "            'fcu_oveFan_activate': 1,\n",
    "            'fcu_oveTSup_u': action['supply_temp'],\n",
    "            'fcu_oveTSup_activate': 1,\n",
    "            'con_oveTSetHea_u': action['heat_setpoint'],\n",
    "            'con_oveTSetHea_activate': 1,\n",
    "            'con_oveTSetCoo_u': action['cool_setpoint'],\n",
    "            'con_oveTSetCoo_activate': 1,\n",
    "        }\n",
    "\n",
    "        resp = requests.post(\n",
    "            f\"{self.url}/advance/{self.testid}\", json=control, timeout=60\n",
    "        )\n",
    "        payload = resp.json().get('payload', {}) or {}\n",
    "\n",
    "        obs = self._get_obs(payload)\n",
    "        reward, reward_detail = self._calc_reward(obs)\n",
    "\n",
    "        sim_time = payload.get(\"time\", 0)\n",
    "        done = sim_time >= STEPS_PER_EPISODE * 900\n",
    "\n",
    "        info = {\n",
    "            \"sim_time\": sim_time,\n",
    "            \"room_temp\": K2C(obs[0]),\n",
    "            \"outdoor_temp\": K2C(obs[1]),\n",
    "            \"reward_detail\": reward_detail,\n",
    "        }\n",
    "        self.prev_action_norm = action_idx / max(1, NUM_ACTIONS - 1)\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def _safe_get(self, payload, key, default):\n",
    "        v = payload.get(key, default)\n",
    "        if v is None:\n",
    "            return default\n",
    "        return v\n",
    "\n",
    "    def _get_obs(self, payload):\n",
    "        if not payload:\n",
    "            return np.zeros(self.obs_dim, dtype=np.float32)\n",
    "\n",
    "        sim_time = payload.get(\"time\", 0)\n",
    "        hour = (sim_time % 86400) / 3600.0\n",
    "\n",
    "        room_temp = self._safe_get(payload, \"zon_reaTRooAir_y\", 293.15)\n",
    "        outdoor_temp = self._safe_get(payload, \"zon_weaSta_reaWeaTDryBul_y\", 283.15)\n",
    "        rel_hum = self._safe_get(payload, \"zon_weaSta_reaWeaRelHum_y\", 0.5)\n",
    "        solar = self._safe_get(payload, \"zon_weaSta_reaWeaHGloHor_y\", 0.0)\n",
    "        wind = self._safe_get(payload, \"zon_weaSta_reaWeaWinSpe_y\", 0.0)\n",
    "        co2 = self._safe_get(payload, \"zon_reaCO2RooAir_y\", 600.0)\n",
    "        p_heating = self._safe_get(payload, \"fcu_reaPHea_y\", 0.0)\n",
    "        p_cooling = self._safe_get(payload, \"fcu_reaPCoo_y\", 0.0)\n",
    "        p_fan = self._safe_get(payload, \"fcu_reaPFan_y\", 0.0)\n",
    "\n",
    "        obs = np.array(\n",
    "            [\n",
    "                room_temp,\n",
    "                outdoor_temp,\n",
    "                rel_hum,\n",
    "                solar / 1000.0,\n",
    "                wind,\n",
    "                co2 / 1000.0,\n",
    "                p_heating / 1000.0,\n",
    "                p_cooling / 1000.0,\n",
    "                p_fan / 1000.0,\n",
    "                np.sin(2 * np.pi * hour / 24),\n",
    "                np.cos(2 * np.pi * hour / 24),\n",
    "                self.prev_action_norm,\n",
    "            ],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        return obs\n",
    "\n",
    "    def _calc_reward(self, obs):\n",
    "        room_temp_c = K2C(obs[0])\n",
    "        p_h, p_c, p_f = obs[6], obs[7], obs[8]\n",
    "\n",
    "        # ã€ä¼˜åŒ–ã€‘Rewardè®¾è®¡ï¼šç¦»èˆ’é€‚åŒºè¶Šè¿œï¼Œæƒ©ç½šè¶Šå¤§ï¼›ä¸comfortableæœ‰æ›´å¤§æƒ©ç½š\n",
    "        if 20.0 <= room_temp_c <= 24.0:\n",
    "            # èˆ’é€‚åŒºå†…ï¼šè·ç¦»22Â°Cè¶Šè¿‘å¥–åŠ±è¶Šé«˜ï¼Œæœ€é«˜+3.0\n",
    "            temp_dev_from_22 = abs(room_temp_c - 22.0)\n",
    "            comfort = 3.0 - 0.15 * (temp_dev_from_22 ** 2)  # 22Â°Cæ—¶+3.0ï¼Œè¾¹ç•Œæ—¶çº¦+0.4\n",
    "        else:\n",
    "            # èˆ’é€‚åŒºå¤–ï¼šåŸºäºè·ç¦»èˆ’é€‚åŒºè¾¹ç•Œçš„è·ç¦»ï¼Œè·ç¦»è¶Šè¿œæƒ©ç½šè¶Šå¤§\n",
    "            if room_temp_c < 20.0:\n",
    "                # ä½äºèˆ’é€‚åŒºï¼šè®¡ç®—è·ç¦»20Â°Cè¾¹ç•Œçš„è·ç¦»\n",
    "                temp_dev_from_boundary = 20.0 - room_temp_c\n",
    "            else:  # room_temp_c > 24.0\n",
    "                # é«˜äºèˆ’é€‚åŒºï¼šè®¡ç®—è·ç¦»24Â°Cè¾¹ç•Œçš„è·ç¦»\n",
    "                temp_dev_from_boundary = room_temp_c - 24.0\n",
    "            \n",
    "            # äºŒæ¬¡æƒ©ç½šï¼šè·ç¦»è¾¹ç•Œè¶Šè¿œï¼Œæƒ©ç½šè¶Šå¤§ï¼ˆå¢å¼ºæƒ©ç½šå¼ºåº¦ï¼‰\n",
    "            comfort = -5.0 * (temp_dev_from_boundary ** 2)  # æ›´å¼ºçš„æƒ©ç½šï¼Œç¡®ä¿ä¼˜å…ˆå›åˆ°èˆ’é€‚åŒº\n",
    "        \n",
    "        # æç«¯æ¸©åº¦é¢å¤–ç¡¬æƒ©ç½šï¼ˆå¢å¼ºï¼‰\n",
    "        if room_temp_c < 19.0 or room_temp_c > 26.0:\n",
    "            comfort -= 25.0  # æ›´å¼ºçš„ç¡¬æƒ©ç½šï¼Œé¿å…æç«¯æ¸©åº¦\n",
    "\n",
    "        # ã€ä¼˜åŒ–ã€‘èƒ½è€—æƒ©ç½šï¼šåœ¨èˆ’é€‚åŒºå†…æƒ©ç½šè¾ƒå°ï¼Œèˆ’é€‚åŒºå¤–æ›´å°ï¼ˆä¼˜å…ˆä¿è¯èˆ’é€‚ï¼‰\n",
    "        if 20.0 <= room_temp_c <= 24.0:\n",
    "            energy = -0.15 * (p_h + p_c) - 0.03 * p_f  # èˆ’é€‚åŒºå†…ï¼šè¾ƒå°æƒ©ç½š\n",
    "        else:\n",
    "            energy = -0.05 * (p_h + p_c) - 0.01 * p_f  # èˆ’é€‚åŒºå¤–ï¼šæ›´å°æƒ©ç½šï¼ˆä¼˜å…ˆæ¢å¤èˆ’é€‚ï¼‰\n",
    "        \n",
    "        # åŠ¨ä½œå¹³æ»‘æ€§ï¼ˆè¾ƒå°æƒé‡ï¼‰\n",
    "        smooth = -0.01 * abs(obs[-1] - self.prev_action_norm)\n",
    "\n",
    "        reward = comfort + energy + smooth\n",
    "        detail = {\n",
    "            \"comfort\": comfort,\n",
    "            \"energy\": energy,\n",
    "            \"smooth\": smooth,\n",
    "            \"room_temp_c\": room_temp_c,\n",
    "            \"in_comfort_zone\": 20.0 <= room_temp_c <= 24.0,\n",
    "        }\n",
    "        return reward, detail\n",
    "\n",
    "    def stop(self):\n",
    "        if self.testid:\n",
    "            try:\n",
    "                requests.put(f\"{self.url}/stop/{self.testid}\", timeout=10)\n",
    "                log(f\"âœ… ç¯å¢ƒå·²åœæ­¢ (testid: {self.testid})\")\n",
    "            except Exception as e:\n",
    "                log(f\"åœæ­¢å¤±è´¥: {e}\", \"WARN\")\n",
    "            finally:\n",
    "                self.testid = None  # æ¸…ç©º testidï¼Œä¸‹æ¬¡ reset æ—¶ä¼šé‡æ–°è·å–\n",
    "\n",
    "# =====================================================================\n",
    "# DQN ç»„ä»¶\n",
    "# =====================================================================\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, hidden=256):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(state_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, action_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity, obs_dim):\n",
    "        self.capacity = capacity\n",
    "        self.obs = np.zeros((capacity, obs_dim), dtype=np.float32)\n",
    "        self.next_obs = np.zeros((capacity, obs_dim), dtype=np.float32)\n",
    "        self.actions = np.zeros(capacity, dtype=np.int64)\n",
    "        self.rewards = np.zeros(capacity, dtype=np.float32)\n",
    "        self.dones = np.zeros(capacity, dtype=np.float32)\n",
    "        self.idx = 0\n",
    "        self.full = False\n",
    "\n",
    "    def add(self, obs, action, reward, done, next_obs):\n",
    "        self.obs[self.idx] = obs\n",
    "        self.next_obs[self.idx] = next_obs\n",
    "        self.actions[self.idx] = action\n",
    "        self.rewards[self.idx] = reward\n",
    "        self.dones[self.idx] = done\n",
    "        self.idx = (self.idx + 1) % self.capacity\n",
    "        if self.idx == 0:\n",
    "            self.full = True\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        max_idx = self.capacity if self.full else self.idx\n",
    "        idxs = np.random.choice(max_idx, batch_size, replace=False)\n",
    "        batch = (\n",
    "            torch.FloatTensor(self.obs[idxs]),\n",
    "            torch.LongTensor(self.actions[idxs]),\n",
    "            torch.FloatTensor(self.rewards[idxs]),\n",
    "            torch.FloatTensor(self.dones[idxs]),\n",
    "            torch.FloatTensor(self.next_obs[idxs]),\n",
    "        )\n",
    "        return batch\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# ç›‘æ§ä¸å¯è§†åŒ–\n",
    "# =====================================================================\n",
    "\n",
    "class Monitor:\n",
    "    def __init__(self, save_dir=\"training_data\"):\n",
    "        self.save_dir = save_dir\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        self.train_rewards = []\n",
    "        self.train_temps = []\n",
    "        self.train_comfort_ratios = []  # èˆ’é€‚åŒºæ—¶é—´æ¯”ä¾‹\n",
    "        self.train_energy_consumption = []  # èƒ½è€—\n",
    "        self.eval_rewards = []\n",
    "        self.eval_episodes = []\n",
    "        \n",
    "        # è¯¦ç»†æ•°æ®è®°å½•\n",
    "        self.episode_data = []  # æ¯episodeçš„è¯¦ç»†æ•°æ®\n",
    "        \n",
    "        # å½“å‰episodeçš„è½¨è¿¹\n",
    "        self.last_actions = []\n",
    "        self.last_temps = []\n",
    "        self.last_outdoor = []\n",
    "        self.last_rewards = []\n",
    "        self.last_comfort_details = []  # èˆ’é€‚åº¦è¯¦æƒ…\n",
    "        self.last_energy_details = []  # èƒ½è€—è¯¦æƒ…\n",
    "        self.last_action_counts = Counter()\n",
    "        \n",
    "        # è®­ç»ƒå†å²ï¼ˆç”¨äºä¿å­˜ï¼‰\n",
    "        self.training_history = {\n",
    "            \"episodes\": [],\n",
    "            \"rewards\": [],\n",
    "            \"temps\": [],\n",
    "            \"comfort_ratios\": [],\n",
    "            \"energy_consumption\": [],\n",
    "            \"eval_episodes\": [],\n",
    "            \"eval_rewards\": [],\n",
    "        }\n",
    "\n",
    "    def log_episode_curves(self, actions, temps, outdoors, rewards, comfort_details=None, energy_details=None):\n",
    "        self.last_actions = actions\n",
    "        self.last_temps = temps\n",
    "        self.last_outdoor = outdoors\n",
    "        self.last_rewards = rewards\n",
    "        self.last_comfort_details = comfort_details or []\n",
    "        self.last_energy_details = energy_details or []\n",
    "        self.last_action_counts = Counter(actions)\n",
    "    \n",
    "    def save_episode_data(self, episode, actions, temps, outdoors, rewards, comfort_details, energy_details):\n",
    "        \"\"\"ä¿å­˜å•ä¸ªepisodeçš„è¯¦ç»†æ•°æ®\"\"\"\n",
    "        episode_data = {\n",
    "            \"episode\": episode,\n",
    "            \"steps\": len(actions),\n",
    "            \"actions\": actions,\n",
    "            \"temperatures\": temps,\n",
    "            \"outdoor_temps\": outdoors,\n",
    "            \"rewards\": rewards,\n",
    "            \"comfort_details\": comfort_details,\n",
    "            \"energy_details\": energy_details,\n",
    "            \"avg_temp\": float(np.mean(temps)) if temps else 0,\n",
    "            \"comfort_ratio\": float(np.mean([1 if 20 <= t <= 24 else 0 for t in temps])) if temps else 0,\n",
    "            \"total_energy\": float(np.sum(energy_details)) if energy_details else 0,\n",
    "        }\n",
    "        self.episode_data.append(episode_data)\n",
    "        \n",
    "        # ä¿å­˜åˆ°JSONæ–‡ä»¶\n",
    "        json_path = os.path.join(self.save_dir, f\"episode_{episode}.json\")\n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(episode_data, f, indent=2)\n",
    "    \n",
    "    def save_training_summary(self):\n",
    "        \"\"\"ä¿å­˜è®­ç»ƒæ€»ç»“\"\"\"\n",
    "        summary = {\n",
    "            \"total_episodes\": len(self.train_rewards),\n",
    "            \"training_history\": self.training_history,\n",
    "            \"final_stats\": {\n",
    "                \"avg_reward\": float(np.mean(self.train_rewards[-50:])) if len(self.train_rewards) >= 50 else float(np.mean(self.train_rewards)) if self.train_rewards else 0,\n",
    "                \"avg_temp\": float(np.mean(self.train_temps[-50:])) if len(self.train_temps) >= 50 else float(np.mean(self.train_temps)) if self.train_temps else 0,\n",
    "                \"avg_comfort_ratio\": float(np.mean(self.train_comfort_ratios[-50:])) if len(self.train_comfort_ratios) >= 50 else float(np.mean(self.train_comfort_ratios)) if self.train_comfort_ratios else 0,\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        summary_path = os.path.join(self.save_dir, \"training_summary.json\")\n",
    "        with open(summary_path, 'w') as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        \n",
    "        # ä¿å­˜CSVæ ¼å¼ï¼ˆä¾¿äºåˆ†æï¼‰\n",
    "        csv_path = os.path.join(self.save_dir, \"training_history.csv\")\n",
    "        with open(csv_path, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['Episode', 'Reward', 'AvgTemp', 'ComfortRatio', 'EnergyConsumption'])\n",
    "            for i in range(len(self.train_rewards)):\n",
    "                writer.writerow([\n",
    "                    i + 1,\n",
    "                    self.train_rewards[i],\n",
    "                    self.train_temps[i],\n",
    "                    self.train_comfort_ratios[i] if i < len(self.train_comfort_ratios) else 0,\n",
    "                    self.train_energy_consumption[i] if i < len(self.train_energy_consumption) else 0,\n",
    "                ])\n",
    "        \n",
    "        log(f\"ğŸ’¾ è®­ç»ƒæ•°æ®å·²ä¿å­˜åˆ° {self.save_dir}\")\n",
    "\n",
    "    def plot(self, save_path=None):\n",
    "        \"\"\"å¢å¼ºç‰ˆè®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–\"\"\"\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "        # 1. è®­ç»ƒå¥–åŠ±\n",
    "        ax = axes[0, 0]\n",
    "        episodes = list(range(1, len(self.train_rewards) + 1))\n",
    "        ax.plot(episodes, self.train_rewards, 'b-', alpha=0.4, label='Raw')\n",
    "        if len(self.train_rewards) >= 10:\n",
    "            # MA(10): éœ€è¦10ä¸ªæ•°æ®ç‚¹ï¼Œä»ç¬¬10ä¸ªepisodeå¼€å§‹\n",
    "            ma = np.convolve(self.train_rewards, np.ones(10) / 10, mode='valid')\n",
    "            ma_episodes = list(range(10, len(self.train_rewards) + 1))  # å¯¹é½åˆ°æ•´æ•°episode\n",
    "            ax.plot(ma_episodes, ma, 'r-', linewidth=2, label='MA(10)')\n",
    "        ax.set_title('Training Reward', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Episode')\n",
    "        ax.set_ylabel('Reward')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # 2. å¹³å‡æ¸©åº¦\n",
    "        ax = axes[0, 1]\n",
    "        ax.plot(self.train_temps, 'g-', linewidth=1.5)\n",
    "        ax.axhspan(20, 24, alpha=0.2, color='green', label='Comfort Zone')\n",
    "        ax.axhline(22, color='r', linestyle='--', linewidth=1.5, label='Target 22Â°C')\n",
    "        ax.set_title('Average Temperature', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Episode')\n",
    "        ax.set_ylabel('Temperature (Â°C)')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # 3. èˆ’é€‚åŒºæ—¶é—´æ¯”ä¾‹\n",
    "        ax = axes[0, 2]\n",
    "        if self.train_comfort_ratios:\n",
    "            ax.plot(self.train_comfort_ratios, 'purple', linewidth=1.5)\n",
    "            ax.axhline(0.8, color='orange', linestyle='--', label='Target 80%')\n",
    "        ax.set_title('Comfort Zone Ratio', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Episode')\n",
    "        ax.set_ylabel('Ratio (0-1)')\n",
    "        ax.set_ylim(0, 1.05)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # 4. èƒ½è€—è¶‹åŠ¿\n",
    "        ax = axes[1, 0]\n",
    "        if self.train_energy_consumption:\n",
    "            ax.plot(self.train_energy_consumption, 'orange', linewidth=1.5)\n",
    "        ax.set_title('Energy Consumption', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Episode')\n",
    "        ax.set_ylabel('Total Energy (kW)')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # 5. è¯„ä¼°å¥–åŠ±\n",
    "        ax = axes[1, 1]\n",
    "        if self.eval_rewards:\n",
    "            ax.plot(self.eval_episodes, self.eval_rewards, 'ro-', markersize=6, linewidth=2)\n",
    "        ax.set_title('Evaluation Reward', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Episode')\n",
    "        ax.set_ylabel('Eval Reward')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # 6. æ¸©åº¦åˆ†å¸ƒï¼ˆæœ€è¿‘50ä¸ªepisodeï¼‰\n",
    "        ax = axes[1, 2]\n",
    "        if len(self.train_temps) >= 50:\n",
    "            recent_temps = self.train_temps[-50:]\n",
    "            ax.hist(recent_temps, bins=20, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "            ax.axvline(22, color='r', linestyle='--', linewidth=2, label='Target 22Â°C')\n",
    "            ax.axvspan(20, 24, alpha=0.2, color='green', label='Comfort Zone')\n",
    "        ax.set_title('Temperature Distribution (Last 50 Episodes)', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Temperature (Â°C)')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "            log(f\"ğŸ“Š å›¾è¡¨å·²ä¿å­˜: {save_path}\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_episode_curves(self, episode, save_dir=None):\n",
    "        if not self.last_actions:\n",
    "            return\n",
    "        steps = range(1, len(self.last_actions) + 1)\n",
    "\n",
    "        decoded = [action_to_values(a) for a in self.last_actions]\n",
    "        fan_seq = [d['fan'] for d in decoded]\n",
    "        supply_seq = [K2C(d['supply_temp']) for d in decoded]\n",
    "        heat_seq = [K2C(d['heat_setpoint']) for d in decoded]\n",
    "        cool_seq = [K2C(d['cool_setpoint']) for d in decoded]\n",
    "\n",
    "        # å¢å¼ºç‰ˆï¼š4è¡Œ3åˆ—ï¼Œæ·»åŠ èˆ’é€‚åº¦å’Œèƒ½è€—\n",
    "        fig, axes = plt.subplots(4, 3, figsize=(20, 16))\n",
    "\n",
    "        ax = axes[0, 0]\n",
    "        ax.plot(steps, self.last_temps, label='Room Temp', linewidth=2, color='blue')\n",
    "        ax.plot(steps, self.last_outdoor, label='Outdoor Temp', alpha=0.6, color='gray', linestyle='--')\n",
    "        ax.axhspan(20, 24, alpha=0.15, color='green', label='Comfort Zone 20-24Â°C')\n",
    "        ax.axhline(22, color='r', linestyle='--', linewidth=1.5, label='Target 22Â°C')\n",
    "        ax.set_title(f'Episode {episode} | Temperature Profile', fontsize=11, fontweight='bold')\n",
    "        ax.set_xlabel('Step (15min)')\n",
    "        ax.set_ylabel('Temperature (Â°C)')\n",
    "        ax.legend(loc='best')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        ax = axes[0, 1]\n",
    "        ax.plot(steps, self.last_rewards, 'tab:orange', linewidth=1.5)\n",
    "        ax.set_title('Step Rewards', fontsize=11, fontweight='bold')\n",
    "        ax.set_xlabel('Step')\n",
    "        ax.set_ylabel('Reward')\n",
    "        ax.axhline(0, color='gray', linestyle='--', alpha=0.5)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # èˆ’é€‚åº¦è¯¦æƒ…\n",
    "        ax = axes[0, 2]\n",
    "        if self.last_comfort_details:\n",
    "            ax.plot(steps, self.last_comfort_details, 'green', linewidth=1.5, label='Comfort Reward')\n",
    "            ax.axhline(0, color='gray', linestyle='--', alpha=0.5)\n",
    "            # æ ‡è®°èˆ’é€‚åŒº\n",
    "            comfort_zones = [1 if 20 <= t <= 24 else 0 for t in self.last_temps]\n",
    "            ax2 = ax.twinx()\n",
    "            ax2.fill_between(steps, 0, comfort_zones, alpha=0.2, color='green', label='In Comfort Zone')\n",
    "            ax2.set_ylabel('Comfort Zone (0/1)', color='green')\n",
    "            ax2.set_ylim(-0.1, 1.1)\n",
    "        ax.set_title('Comfort Reward Details', fontsize=11, fontweight='bold')\n",
    "        ax.set_xlabel('Step')\n",
    "        ax.set_ylabel('Comfort Reward')\n",
    "        ax.legend(loc='upper left')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        ax = axes[1, 0]\n",
    "        ax.scatter(steps, self.last_actions, s=15, alpha=0.6, color='steelblue')\n",
    "        ax.set_title('Action Index per Step', fontsize=11, fontweight='bold')\n",
    "        ax.set_xlabel('Step')\n",
    "        ax.set_ylabel('Action Index (0-23)')\n",
    "        ax.set_ylim(-1, max(self.last_actions) + 2)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        ax = axes[1, 1]\n",
    "        items = sorted(self.last_action_counts.items(), key=lambda x: x[0])\n",
    "        if items:\n",
    "            labels, counts = zip(*items)\n",
    "            ax.bar(labels, counts, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "        ax.set_title('Action Usage Histogram', fontsize=11, fontweight='bold')\n",
    "        ax.set_xlabel('Action Index')\n",
    "        ax.set_ylabel('Usage Count')\n",
    "        ax.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "        ax = axes[2, 0]\n",
    "        ax.plot(steps, supply_seq, label='Supply Temp', linewidth=1.5, color='red')\n",
    "        ax.plot(steps, heat_seq, label='Heat Setpoint', linewidth=1.5, color='orange')\n",
    "        ax.plot(steps, cool_seq, label='Cool Setpoint', linewidth=1.5, color='blue')\n",
    "        ax.set_title('Supply Temperature & Setpoints', fontsize=11, fontweight='bold')\n",
    "        ax.set_xlabel('Step')\n",
    "        ax.set_ylabel('Temperature (Â°C)')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        ax = axes[2, 1]\n",
    "        ax.plot(steps, fan_seq, label='Fan u', color='tab:purple', linewidth=1.5)\n",
    "        ax.set_title('Fan Control', fontsize=11, fontweight='bold')\n",
    "        ax.set_xlabel('Step')\n",
    "        ax.set_ylabel('0-1')\n",
    "        ax.set_ylim(0, 1.05)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # èƒ½è€—è¯¦æƒ…\n",
    "        ax = axes[2, 2]\n",
    "        if self.last_energy_details:\n",
    "            ax.plot(steps, self.last_energy_details, 'orange', linewidth=1.5, label='Energy Cost')\n",
    "            ax.set_title('Energy Consumption per Step', fontsize=11, fontweight='bold')\n",
    "            ax.set_xlabel('Step')\n",
    "            ax.set_ylabel('Energy (kW)')\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "\n",
    "        # æ¸©åº¦åˆ†å¸ƒç›´æ–¹å›¾\n",
    "        ax = axes[3, 0]\n",
    "        if self.last_temps:\n",
    "            ax.hist(self.last_temps, bins=20, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "            ax.axvline(22, color='r', linestyle='--', linewidth=2, label='Target 22Â°C')\n",
    "            ax.axvspan(20, 24, alpha=0.2, color='green', label='Comfort Zone')\n",
    "            ax.set_title('Temperature Distribution', fontsize=11, fontweight='bold')\n",
    "            ax.set_xlabel('Temperature (Â°C)')\n",
    "            ax.set_ylabel('Frequency')\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "        # å¥–åŠ±åˆ†è§£ï¼ˆèˆ’é€‚åº¦ vs èƒ½è€—ï¼‰\n",
    "        ax = axes[3, 1]\n",
    "        if self.last_comfort_details and self.last_energy_details:\n",
    "            # ç´¯ç§¯å¥–åŠ±\n",
    "            cum_comfort = np.cumsum(self.last_comfort_details)\n",
    "            cum_energy = np.cumsum([-e for e in self.last_energy_details])  # è´Ÿå€¼è¡¨ç¤ºæƒ©ç½š\n",
    "            ax.plot(steps, cum_comfort, 'g-', linewidth=2, label='Cumulative Comfort')\n",
    "            ax.plot(steps, cum_energy, 'orange', linewidth=2, label='Cumulative Energy (neg)')\n",
    "            ax.axhline(0, color='gray', linestyle='--', alpha=0.5)\n",
    "            ax.set_title('Cumulative Reward Components', fontsize=11, fontweight='bold')\n",
    "            ax.set_xlabel('Step')\n",
    "            ax.set_ylabel('Cumulative Reward')\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "\n",
    "        # ç»Ÿè®¡ä¿¡æ¯\n",
    "        ax = axes[3, 2]\n",
    "        ax.axis('off')\n",
    "        avg_temp = np.mean(self.last_temps) if self.last_temps else 0\n",
    "        comfort_ratio = np.mean([1 if 20 <= t <= 24 else 0 for t in self.last_temps]) if self.last_temps else 0\n",
    "        total_energy = sum(self.last_energy_details) if self.last_energy_details else 0\n",
    "        total_reward = sum(self.last_rewards) if self.last_rewards else 0\n",
    "        avg_comfort_reward = np.mean(self.last_comfort_details) if self.last_comfort_details else 0\n",
    "        \n",
    "        stats_text = f\"\"\"Episode {episode} Statistics\n",
    "{'='*50}\n",
    "Total Reward: {total_reward:.2f}\n",
    "Avg Temperature: {avg_temp:.2f}Â°C\n",
    "Comfort Zone Ratio: {comfort_ratio*100:.1f}%\n",
    "Total Energy: {total_energy:.2f} kW\n",
    "Avg Comfort Reward: {avg_comfort_reward:.2f}\n",
    "Steps: {len(self.last_actions)}\n",
    "Unique Actions: {len(self.last_action_counts)}\n",
    "\"\"\"\n",
    "        ax.text(0.1, 0.5, stats_text, fontsize=10, family='monospace',\n",
    "                verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        if save_dir:\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            fig.savefig(os.path.join(save_dir, f\"dqn_curves_ep{episode}.png\"), dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "# =====================================================================\n",
    "# è®­ç»ƒå¾ªç¯\n",
    "# =====================================================================\n",
    "\n",
    "def linear_eps(step):\n",
    "    return max(EPS_END, EPS_START - (EPS_START - EPS_END) * step / EPS_DECAY_STEPS)\n",
    "\n",
    "\n",
    "def soft_update(target, online, tau):\n",
    "    for tp, op in zip(target.parameters(), online.parameters()):\n",
    "        tp.data.copy_(tau * op.data + (1 - tau) * tp.data)\n",
    "\n",
    "\n",
    "def train():\n",
    "    print(\"=\" * 70, flush=True)\n",
    "    print(\"ğŸš€ BOPTEST DQN è®­ç»ƒ (ä¿®å¤ç‰ˆ)\", flush=True)\n",
    "    print(\"=\" * 70, flush=True)\n",
    "\n",
    "    log(\"æ£€æŸ¥BOPTESTè¿æ¥...\")\n",
    "    try:\n",
    "        resp = requests.get(f\"{BOPTEST_URL}/testcases\", timeout=10)\n",
    "        log(\"âœ… è¿æ¥æˆåŠŸ!\")\n",
    "    except Exception as e:\n",
    "        log(f\"âŒ è¿æ¥å¤±è´¥: {e}\", \"ERROR\")\n",
    "        log(f\"è¯·ç¡®è®¤BOPTEST_URLæ˜¯å¦æ­£ç¡®: {BOPTEST_URL}\", \"ERROR\")\n",
    "        return None\n",
    "\n",
    "    env = BOPTESTEnv()\n",
    "    os.makedirs(DATA_SAVE_DIR, exist_ok=True)\n",
    "    os.makedirs(PLOT_SAVE_DIR, exist_ok=True)\n",
    "    monitor = Monitor(save_dir=DATA_SAVE_DIR)\n",
    "\n",
    "    q_net = QNetwork(env.obs_dim, env.action_dim)\n",
    "    target_net = QNetwork(env.obs_dim, env.action_dim)\n",
    "    target_net.load_state_dict(q_net.state_dict())\n",
    "    optimizer = optim.Adam(q_net.parameters(), lr=LR)\n",
    "\n",
    "    buffer = ReplayBuffer(BUFFER_SIZE, env.obs_dim)\n",
    "\n",
    "    global_step = 0\n",
    "    best_eval = -1e9\n",
    "\n",
    "    for episode in range(1, TOTAL_EPISODES + 1):\n",
    "        print(f\"\\n{'=' * 60}\", flush=True)\n",
    "        print(f\"ğŸ“Š Episode {episode}/{TOTAL_EPISODES}\", flush=True)\n",
    "        print(f\"{'=' * 60}\", flush=True)\n",
    "        \n",
    "        try:\n",
    "            state = env.reset()\n",
    "        except Exception as e:\n",
    "            log(f\"âŒ Resetå¤±è´¥: {e}\", \"ERROR\")\n",
    "            env.stop()\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "\n",
    "        total_reward = 0.0\n",
    "        temps = []\n",
    "        actions_seq = []\n",
    "        rewards_seq = []\n",
    "        outdoor_seq = []\n",
    "        comfort_details = []  # æ”¶é›†èˆ’é€‚åº¦è¯¦æƒ…\n",
    "        energy_details = []  # æ”¶é›†èƒ½è€—è¯¦æƒ…\n",
    "\n",
    "        for step in range(STEPS_PER_EPISODE):\n",
    "            eps = linear_eps(global_step)\n",
    "            with torch.no_grad():\n",
    "                q_vals_all = q_net(torch.FloatTensor(state).unsqueeze(0)).squeeze(0)\n",
    "            \n",
    "            if np.random.rand() < eps:\n",
    "                action = np.random.randint(env.action_dim)\n",
    "            else:\n",
    "                action = int(q_vals_all.argmax().item())\n",
    "\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            buffer.add(state, action, reward, float(done), next_state)\n",
    "\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            temps.append(info[\"room_temp\"])\n",
    "            actions_seq.append(action)\n",
    "            rewards_seq.append(reward)\n",
    "            outdoor_seq.append(info[\"outdoor_temp\"])\n",
    "            \n",
    "            # æ”¶é›†è¯¦ç»†ä¿¡æ¯\n",
    "            rd = info[\"reward_detail\"]\n",
    "            comfort_details.append(rd[\"comfort\"])\n",
    "            energy_details.append(abs(rd[\"energy\"]))  # èƒ½è€—ç»å¯¹å€¼\n",
    "            \n",
    "            global_step += 1\n",
    "\n",
    "            if (step + 1) % 10 == 0:\n",
    "                top3_q, top3_actions = torch.topk(q_vals_all, min(3, env.action_dim))\n",
    "                top3_str = \", \".join([f\"A{a.item()}:Q={q.item():.2f}\" for q, a in zip(top3_q, top3_actions)])\n",
    "                print(\n",
    "                    f\"  Step {step+1:3d} | \"\n",
    "                    f\"å®¤æ¸©={info['room_temp']:5.1f}Â°C | \"\n",
    "                    f\"å®¤å¤–={info['outdoor_temp']:5.1f}Â°C | \"\n",
    "                    f\"R={reward:+6.2f} | \"\n",
    "                    f\"åŠ¨ä½œ={action:2d} | \"\n",
    "                    f\"{action_to_string(action)}\",\n",
    "                    flush=True,\n",
    "                )\n",
    "                print(f\"           Top3 Qå€¼: [{top3_str}] | eps={eps:.3f}\", flush=True)\n",
    "                rd = info[\"reward_detail\"]\n",
    "                print(\n",
    "                    f\"           ç»†åˆ†: comfort={rd['comfort']:+.2f}, energy={rd['energy']:+.2f}, smooth={rd['smooth']:+.2f}\",\n",
    "                    flush=True,\n",
    "                )\n",
    "\n",
    "            if buffer.idx >= MIN_REPLAY_SIZE or buffer.full:\n",
    "                obs_b, act_b, rew_b, done_b, nxt_b = buffer.sample(BATCH_SIZE)\n",
    "                with torch.no_grad():\n",
    "                    target_q = target_net(nxt_b).max(dim=1)[0]\n",
    "                    target = rew_b + GAMMA * (1 - done_b) * target_q\n",
    "                q_vals = q_net(obs_b).gather(1, act_b.unsqueeze(1)).squeeze(1)\n",
    "                loss = nn.functional.mse_loss(q_vals, target)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(q_net.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "                if global_step % TARGET_UPDATE == 0:\n",
    "                    soft_update(target_net, q_net, TAU)\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        avg_temp = np.mean(temps) if temps else 0\n",
    "        comfort_ratio = np.mean([1 if 20 <= t <= 24 else 0 for t in temps]) if temps else 0\n",
    "        total_energy = np.sum(energy_details) if energy_details else 0\n",
    "        \n",
    "        monitor.train_rewards.append(total_reward)\n",
    "        monitor.train_temps.append(avg_temp)\n",
    "        monitor.train_comfort_ratios.append(comfort_ratio)\n",
    "        monitor.train_energy_consumption.append(total_energy)\n",
    "        \n",
    "        # æ›´æ–°è®­ç»ƒå†å²\n",
    "        monitor.training_history[\"episodes\"].append(episode)\n",
    "        monitor.training_history[\"rewards\"].append(float(total_reward))\n",
    "        monitor.training_history[\"temps\"].append(float(avg_temp))\n",
    "        monitor.training_history[\"comfort_ratios\"].append(float(comfort_ratio))\n",
    "        monitor.training_history[\"energy_consumption\"].append(float(total_energy))\n",
    "        \n",
    "        # è®°å½•episodeæ›²çº¿\n",
    "        monitor.log_episode_curves(actions_seq, temps, outdoor_seq, rewards_seq, \n",
    "                                   comfort_details, energy_details)\n",
    "        \n",
    "        # ä¿å­˜episodeè¯¦ç»†æ•°æ®\n",
    "        monitor.save_episode_data(episode, actions_seq, temps, outdoor_seq, \n",
    "                                 rewards_seq, comfort_details, energy_details)\n",
    "\n",
    "        action_counts = Counter(actions_seq)\n",
    "        unique_actions = len(action_counts)\n",
    "        most_common = sorted(action_counts.items(), key=lambda x: -x[1])[:3]\n",
    "        \n",
    "        print(f\"\\nâœ… Episode {episode} å®Œæˆ\", flush=True)\n",
    "        print(f\"   æ€»å¥–åŠ±: {total_reward:.1f}\", flush=True)\n",
    "        print(f\"   å¹³å‡å®¤æ¸©: {avg_temp:.1f}Â°C (ç›®æ ‡ 20-24Â°C)\", flush=True)\n",
    "        print(f\"   èˆ’é€‚åŒºæ—¶é—´æ¯”ä¾‹: {comfort_ratio*100:.1f}%\", flush=True)\n",
    "        print(f\"   æ€»èƒ½è€—: {total_energy:.2f} kW\", flush=True)\n",
    "        print(f\"   Epsilon: {eps:.3f} | Buffer: {buffer.idx if not buffer.full else buffer.capacity}/{buffer.capacity}\", flush=True)\n",
    "        print(f\"   ä½¿ç”¨äº† {unique_actions} ç§ä¸åŒåŠ¨ä½œ\", flush=True)\n",
    "        print(\n",
    "            f\"   æœ€å¸¸ç”¨åŠ¨ä½œ: {[(a, action_to_string(a), c) for a, c in most_common]}\",\n",
    "            flush=True,\n",
    "        )\n",
    "\n",
    "        env.stop()\n",
    "        \n",
    "        # æ¯10ä¸ªepisodeä¿å­˜ä¸€æ¬¡è®­ç»ƒæ€»ç»“ï¼ˆè½»é‡çº§ï¼‰\n",
    "        if episode % 10 == 0:\n",
    "            monitor.save_training_summary()\n",
    "\n",
    "        if episode % EVAL_FREQUENCY == 0:\n",
    "            eval_rewards = []\n",
    "            for _ in range(2):\n",
    "                s = env.reset()\n",
    "                ep_r = 0.0\n",
    "                for _ in range(STEPS_PER_EPISODE):\n",
    "                    with torch.no_grad():\n",
    "                        a = int(q_net(torch.FloatTensor(s).unsqueeze(0)).argmax().item())\n",
    "                    s, r, d, _ = env.step(a)\n",
    "                    ep_r += r\n",
    "                    if d:\n",
    "                        break\n",
    "                eval_rewards.append(ep_r)\n",
    "                env.stop()\n",
    "            avg_eval = float(np.mean(eval_rewards)) if eval_rewards else 0\n",
    "            monitor.eval_episodes.append(episode)\n",
    "            monitor.eval_rewards.append(avg_eval)\n",
    "            print(f\"  ğŸ” Eval avg reward: {avg_eval:.2f}\", flush=True)\n",
    "            if avg_eval > best_eval:\n",
    "                best_eval = avg_eval\n",
    "                torch.save(q_net.state_dict(), \"best_dqn.pth\")\n",
    "                log(f\"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ best_dqn.pth | eval={avg_eval:.2f}\")\n",
    "\n",
    "            # ä¿å­˜å¹¶æ˜¾ç¤ºè®­ç»ƒå›¾è¡¨\n",
    "            plot_path = os.path.join(PLOT_SAVE_DIR, f\"training_progress_ep{episode}.png\")\n",
    "            monitor.plot(save_path=plot_path)\n",
    "            monitor.plot_episode_curves(episode, PLOT_SAVE_DIR)\n",
    "            \n",
    "            # ä¿å­˜è®­ç»ƒæ€»ç»“\n",
    "            monitor.save_training_summary()\n",
    "\n",
    "    # ä¿å­˜æœ€ç»ˆæ¨¡å‹\n",
    "    torch.save(q_net.state_dict(), \"final_dqn.pth\")\n",
    "    log(\"è®­ç»ƒç»“æŸï¼Œå·²ä¿å­˜ final_dqn.pth\")\n",
    "    \n",
    "    # ä¿å­˜æœ€ç»ˆè®­ç»ƒæ€»ç»“\n",
    "    monitor.save_training_summary()\n",
    "    \n",
    "    # ç”Ÿæˆæœ€ç»ˆå›¾è¡¨\n",
    "    final_plot_path = os.path.join(PLOT_SAVE_DIR, \"training_final.png\")\n",
    "    monitor.plot(save_path=final_plot_path)\n",
    "    monitor.plot_episode_curves(\"final\", PLOT_SAVE_DIR)\n",
    "    \n",
    "    log(f\"ğŸ“Š æ‰€æœ‰è®­ç»ƒæ•°æ®å·²ä¿å­˜åˆ°: {DATA_SAVE_DIR}\")\n",
    "    log(f\"ğŸ“ˆ æ‰€æœ‰å›¾è¡¨å·²ä¿å­˜åˆ°: {PLOT_SAVE_DIR}\")\n",
    "    \n",
    "    return q_net\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ“Œ DQN ä»£ç å·²åŠ è½½ (ä¿®å¤ç‰ˆ)\")\n",
    "print(\"åŠ¨ä½œç©ºé—´:\", NUM_ACTIONS)\n",
    "print(\"è¿è¡Œ: train()\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93e8cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸš€ BOPTEST DQN è®­ç»ƒ (ä¿®å¤ç‰ˆ)\n",
      "======================================================================\n",
      "[17:23:59] INFO  | æ£€æŸ¥BOPTESTè¿æ¥...\n",
      "[17:23:59] INFO  | âœ… è¿æ¥æˆåŠŸ!\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Episode 1/500\n",
      "============================================================\n",
      "[17:23:59] INFO  | å¼€å§‹é‡ç½®ç¯å¢ƒ...\n",
      "[17:23:59] INFO  | é€‰æ‹©æµ‹è¯•æ¡ˆä¾‹: bestest_air\n",
      "[17:23:59] INFO  | å°è¯•é€‰æ‹©æµ‹è¯•æ¡ˆä¾‹ (å°è¯• 1/3)...\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2d296f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
