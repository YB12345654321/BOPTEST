{
  "total_episodes": 10,
  "training_history": {
    "episodes": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10
    ],
    "rewards": [
      213.1120788590337,
      186.74713244102188,
      228.8835527083694,
      264.2055364935537,
      256.59871088166295,
      248.85549771411445,
      194.64855793459827,
      241.9676760019889,
      302.2016319778149,
      195.1702431327553
    ],
    "temps": [
      20.944111392372548,
      20.688434801603634,
      21.126240298622548,
      21.225651469983568,
      21.444858269942447,
      21.190015612150507,
      20.9595044587788,
      21.500814337479454,
      21.84223247327304,
      21.616328831722875
    ],
    "comfort_ratios": [
      0.6947368421052632,
      0.6736842105263158,
      0.6736842105263158,
      0.7052631578947368,
      0.6842105263157895,
      0.6842105263157895,
      0.631578947368421,
      0.6947368421052632,
      0.7684210526315789,
      0.6210526315789474
    ],
    "energy_consumption": [
      5.012579591348768,
      4.98345229210332,
      4.986686130657327,
      4.990277713858524,
      4.932766143041665,
      5.124755765921436,
      4.847967973959168,
      4.733402014533058,
      4.871540198684668,
      4.484882909315639
    ],
    "eval_episodes": [],
    "eval_rewards": []
  },
  "final_stats": {
    "avg_reward": 233.23906181449132,
    "avg_temp": 21.253819194592943,
    "avg_comfort_ratio": 0.6831578947368422
  }
}