{
  "total_episodes": 10,
  "training_history": {
    "episodes": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10
    ],
    "rewards": [
      -35552.240791452925,
      -33895.437173385544,
      -39655.03027772786,
      -37895.901632439534,
      -32935.58661162135,
      -33328.689663197554,
      -32139.583274647284,
      -28458.71332361359,
      -28880.82775691659,
      -27713.5599238026
    ],
    "temps": [
      16.354761379297713,
      16.55944991141622,
      16.011638486858224,
      16.103476009488375,
      16.598375432725263,
      16.640237522324362,
      16.758772892643385,
      17.102072073472588,
      17.143547054919935,
      17.280804991274156
    ],
    "comfort_ratios": [
      0.1524008350730689,
      0.15866388308977036,
      0.12108559498956159,
      0.13569937369519833,
      0.1544885177453027,
      0.1837160751565762,
      0.19206680584551147,
      0.1732776617954071,
      0.23382045929018788,
      0.20250521920668058
    ],
    "energy_consumption": [
      34.49735462845536,
      34.496392226319294,
      31.299289990819524,
      32.48363686733762,
      35.76729527712334,
      35.44696349911217,
      36.44062526199268,
      37.53373509041033,
      40.03483151579276,
      38.367448998295586
    ],
    "eval_episodes": [],
    "eval_rewards": []
  },
  "final_stats": {
    "avg_reward": -33045.55704288048,
    "avg_temp": 16.655313575442023,
    "avg_comfort_ratio": 0.1707724425887265
  }
}