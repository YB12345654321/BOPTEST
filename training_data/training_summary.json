{
  "total_episodes": 10,
  "training_history": {
    "episodes": [
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10
    ],
    "rewards": [
      -9461.301954455728,
      -9329.98831384753,
      -8589.993252829043,
      -9659.463278190775,
      -9195.28632766231,
      -9258.546156488459,
      -11208.095111088918,
      -9426.562768742351,
      -10059.046556374395,
      -10116.072437792749
    ],
    "temps": [
      17.681933945261388,
      17.59658826258796,
      17.97293023713598,
      17.670033847349494,
      17.527427761217705,
      17.624068143355302,
      17.051941365346877,
      17.620111083984394,
      17.35392861890545,
      17.576002638252636
    ],
    "comfort_ratios": [
      0.24607329842931938,
      0.18848167539267016,
      0.19895287958115182,
      0.20418848167539266,
      0.20418848167539266,
      0.2513089005235602,
      0.17801047120418848,
      0.17277486910994763,
      0.17801047120418848,
      0.18324607329842932
    ],
    "energy_consumption": [
      11.214567071818745,
      10.352598389671185,
      10.924167136041214,
      10.676516811787149,
      10.852348331997636,
      11.863872067062184,
      9.623576656910593,
      10.325774209438823,
      9.823384439188521,
      9.84190973018296
    ],
    "eval_episodes": [],
    "eval_rewards": []
  },
  "final_stats": {
    "avg_reward": -9630.435615747225,
    "avg_temp": 17.567496590339722,
    "avg_comfort_ratio": 0.20052356020942405
  }
}