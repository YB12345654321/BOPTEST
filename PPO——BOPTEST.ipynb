{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f61e0f-2ae7-4444-9789-df87483aadf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ“Œ PPOè®­ç»ƒä»£ç å·²åŠ è½½ (å¼ºåŒ–ç‰ˆ)\n",
      "============================================================\n",
      "\n",
      "BOPTEST URL: http://localhost\n",
      "åŠ¨ä½œç©ºé—´: 24 ä¸ªåŠ¨ä½œ\n",
      "ç†µç³»æ•°: 0.05 (è¶Šå¤§æ¢ç´¢è¶Šå¤š)\n",
      "\n",
      "è¿è¡Œ: train()\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "BOPTEST HVAC PPO è®­ç»ƒ - å¼ºåŒ–ç‰ˆ\n",
    "- æ›´æ–°åŠ¨ä½œç©ºé—´ï¼ˆç‰©ç†èŒƒå›´å†…çš„ç¦»æ•£ç»„åˆï¼Œå¼ºåˆ¶ heat<coolï¼‰\n",
    "- ä¸°å¯Œè§‚æµ‹ï¼ˆå¤©æ°”/è¾ç…§/CO2/æ—¶é—´/ä¸Šä¸€æ­¥åŠ¨ä½œï¼‰\n",
    "- å¥–åŠ±=èˆ’é€‚åº¦äºŒæ¬¡æƒ©ç½š + èƒ½è€—æƒ©ç½š + åŠ¨ä½œå¹³æ»‘\n",
    "- GAE æœ«çŠ¶æ€ bootstrapï¼Œè¶…å‚æ•°æ›´ç¨³ï¼ˆæ›´å° lrï¼Œç¨é«˜ç†µç³»æ•°ï¼‰\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# =====================================================================\n",
    "# é…ç½®å‚æ•°\n",
    "# =====================================================================\n",
    "BOPTEST_URL = os.getenv(\"BOPTEST_URL\", \"http://localhost:80\")  # ä¸ DQN ä¿æŒä¸€è‡´\n",
    "TESTCASE_NAME = \"bestest_air\"\n",
    "\n",
    "# è®­ç»ƒå‚æ•°ï¼ˆæ‹‰é•¿è®­ç»ƒï¼Œæ›´ç¨³æ¢ç´¢ï¼‰\n",
    "# ç»™ä½  10 å°æ—¶é¢„ç®—ï¼Œç›´æ¥é•¿è·‘ 500 ep\n",
    "TOTAL_EPISODES = 500\n",
    "EVAL_FREQUENCY = 20\n",
    "STEPS_PER_EPISODE = 96  # 1 day (96 steps = 1 day, 15min per step)\n",
    "PLOT_SAVE_DIR = \"training_output\"\n",
    "DATA_SAVE_DIR = \"training_data\"  # æ•°æ®ä¿å­˜ç›®å½•\n",
    "\n",
    "# PPO è¶…å‚æ•°ï¼ˆç¨³å¥æ”¶æ•›ï¼Œå¯åœ¨æ­¤åŸºç¡€ä¸Šå°å¹…å¾®è°ƒï¼‰\n",
    "PPO_EPOCHS = 5\n",
    "PPO_CLIP = 0.2\n",
    "GAMMA = 0.99\n",
    "GAE_LAMBDA = 0.95\n",
    "# å·²æ”¹ä¸ºåˆ†åˆ«è®¾ç½®actorå’Œcriticå­¦ä¹ ç‡\n",
    "LEARNING_RATE_ACTOR = 1e-4   # Actorå­¦ä¹ ç‡ï¼šå°ä¸€ç‚¹ï¼Œæ›´ç¨³å®š\n",
    "LEARNING_RATE_CRITIC = 5e-4  # Criticå­¦ä¹ ç‡ï¼šå¤§ä¸€ç‚¹ï¼Œå…ˆå­¦å¥½ä»·å€¼ä¼°è®¡\n",
    "ENTROPY_COEF = 0.05           # ç•¥é«˜æ¢ç´¢ï¼Œé•¿è·‘æ›´ç¨³\n",
    "VALUE_COEF = 0.5\n",
    "MAX_GRAD_NORM = 0.5\n",
    "MINI_BATCH_SIZE = 256         # é€‚å½“æ”¾å¤§ batchï¼Œæ¢¯åº¦æ›´å¹³æ»‘\n",
    "\n",
    "# =====================================================================\n",
    "# åŠ¨ä½œç©ºé—´ï¼ˆä¸ DQN ä¿æŒä¸€è‡´ï¼‰\n",
    "# =====================================================================\n",
    "# èŒƒå›´æ¥æºï¼š\n",
    "#  - fcu_oveFan_u: 0~1\n",
    "#  - fcu_oveTSup_u: 285.15~313.15 K\n",
    "#  - con_oveTSetHea_u / con_oveTSetCoo_u: 278.15~308.15 K\n",
    "# å¼ºåˆ¶ cool >= heat + 1.5K ä»¥ä¿è¯æ­»åŒº\n",
    "# 3 (fan) x 2 (supply) x 2 (heat) x 2 (cool) = 24 actions\n",
    "FAN_LEVELS = [0.3, 0.6, 0.9]\n",
    "SUPPLY_TEMP_LEVELS = [288.15, 296.15]\n",
    "HEAT_SETPOINT_LEVELS = [294.15, 296.15]\n",
    "COOL_SETPOINT_LEVELS = [299.15, 301.15]\n",
    "\n",
    "NUM_ACTIONS = (\n",
    "    len(FAN_LEVELS)\n",
    "    * len(SUPPLY_TEMP_LEVELS)\n",
    "    * len(HEAT_SETPOINT_LEVELS)\n",
    "    * len(COOL_SETPOINT_LEVELS)\n",
    ")\n",
    "\n",
    "# =====================================================================\n",
    "# å·¥å…·å‡½æ•°\n",
    "# =====================================================================\n",
    "\n",
    "def log(msg, level=\"INFO\"):\n",
    "    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(f\"[{timestamp}] {level:5s} | {msg}\", flush=True)\n",
    "\n",
    "def safe_json(resp, context: str = \"\"):\n",
    "    try:\n",
    "        return resp.json()\n",
    "    except Exception as e:\n",
    "        log(\n",
    "            f\"JSON è§£æå¤±è´¥({context}): {type(e).__name__}: {e}. status={resp.status_code}, text={resp.text[:300]}\",\n",
    "            \"ERROR\",\n",
    "        )\n",
    "        return None\n",
    "\n",
    "def K2C(k):\n",
    "    return k - 273.15\n",
    "\n",
    "def action_to_values(action_idx):\n",
    "    \"\"\"å°†ç´¢å¼•è§£ç ä¸ºå„æ§åˆ¶é‡å¹¶åšå®‰å…¨è£å‰ª\"\"\"\n",
    "    cool_idx = action_idx % len(COOL_SETPOINT_LEVELS)\n",
    "    remaining = action_idx // len(COOL_SETPOINT_LEVELS)\n",
    "    heat_idx = remaining % len(HEAT_SETPOINT_LEVELS)\n",
    "    remaining //= len(HEAT_SETPOINT_LEVELS)\n",
    "    supply_idx = remaining % len(SUPPLY_TEMP_LEVELS)\n",
    "    fan_idx = remaining // len(SUPPLY_TEMP_LEVELS)\n",
    "\n",
    "    v = {\n",
    "        'fan': FAN_LEVELS[fan_idx],\n",
    "        'supply_temp': SUPPLY_TEMP_LEVELS[supply_idx],\n",
    "        'heat_setpoint': HEAT_SETPOINT_LEVELS[heat_idx],\n",
    "        'cool_setpoint': COOL_SETPOINT_LEVELS[cool_idx],\n",
    "    }\n",
    "\n",
    "    # å¼ºåˆ¶ cool > heat + 1.5K\n",
    "    if v['cool_setpoint'] <= v['heat_setpoint'] + 1.5:\n",
    "        v['cool_setpoint'] = v['heat_setpoint'] + 1.5\n",
    "\n",
    "    # ç‰©ç†èŒƒå›´è£å‰ª\n",
    "    v['fan'] = float(np.clip(v['fan'], 0.0, 1.0))\n",
    "    v['supply_temp'] = float(np.clip(v['supply_temp'], 285.15, 313.15))\n",
    "    v['heat_setpoint'] = float(np.clip(v['heat_setpoint'], 278.15, 308.15))\n",
    "    v['cool_setpoint'] = float(np.clip(v['cool_setpoint'], 278.15, 308.15))\n",
    "    return v\n",
    "\n",
    "def action_to_string(action_idx):\n",
    "    v = action_to_values(action_idx)\n",
    "    return (\n",
    "        f\"Fan={v['fan']:.1f}|ä¾›é£={K2C(v['supply_temp']):.0f}Â°C|\"\n",
    "        f\"çƒ­è®¾={K2C(v['heat_setpoint']):.1f}Â°C|å†·è®¾={K2C(v['cool_setpoint']):.1f}Â°C\"\n",
    "    )\n",
    "\n",
    "# =====================================================================\n",
    "# ç¯å¢ƒ\n",
    "# =====================================================================\n",
    "\n",
    "class BOPTESTEnv:\n",
    "    def __init__(self):\n",
    "        self.url = BOPTEST_URL\n",
    "        self.testid = None\n",
    "        self.obs_dim = 12  # æ‰©å±•è§‚æµ‹\n",
    "        self.action_dim = NUM_ACTIONS\n",
    "        self.prev_action_norm = 0.0\n",
    "\n",
    "    def _select_testcase(self):\n",
    "        log(f\"é€‰æ‹©æµ‹è¯•æ¡ˆä¾‹: {TESTCASE_NAME}\")\n",
    "        try:\n",
    "            resp = requests.post(\n",
    "                f\"{self.url}/testcases/{TESTCASE_NAME}/select\", timeout=30\n",
    "            )\n",
    "            if resp.status_code == 200:\n",
    "                data = safe_json(resp, \"select testcase\")\n",
    "                if data:\n",
    "                    self.testid = data.get('testid')\n",
    "                    if self.testid:\n",
    "                        log(f\"âœ… Test ID: {self.testid}\")\n",
    "                        time.sleep(3)\n",
    "                        return True\n",
    "                    else:\n",
    "                        log(\"âŒ æœªè¿”å› testid\", \"ERROR\")\n",
    "            else:\n",
    "                log(\n",
    "                    f\"âŒ é€‰æ‹©å¤±è´¥ï¼ŒçŠ¶æ€ç ={resp.status_code}, å“åº”={resp.text[:200]}\",\n",
    "                    \"ERROR\",\n",
    "                )\n",
    "        except Exception as e:\n",
    "            log(f\"âŒ é€‰æ‹©å¤±è´¥: {e}\", \"ERROR\")\n",
    "        return False\n",
    "\n",
    "    def reset(self):\n",
    "        # è‹¥æ— æ³•é€‰æ‹©æµ‹è¯•æ¡ˆä¾‹ï¼Œå…ˆæ‰“å°å¯ç”¨æ¡ˆä¾‹ä¾¿äºè¯Šæ–­\n",
    "        if not self.testid:\n",
    "            try:\n",
    "                list_resp = requests.get(f\"{self.url}/testcases\", timeout=10)\n",
    "                if list_resp.status_code == 200:\n",
    "                    data = safe_json(list_resp, \"list testcases\")\n",
    "                    if data is not None:\n",
    "                        log(f\"å¯ç”¨æµ‹è¯•æ¡ˆä¾‹: {list(data)}\", \"DEBUG\")\n",
    "                else:\n",
    "                    log(\n",
    "                        f\"è·å–æµ‹è¯•æ¡ˆä¾‹å¤±è´¥: {list_resp.status_code}, text={list_resp.text[:200]}\",\n",
    "                        \"WARN\",\n",
    "                    )\n",
    "            except Exception as e:\n",
    "                log(f\"è·å–æµ‹è¯•æ¡ˆä¾‹åˆ—è¡¨å¤±è´¥: {e}\", \"WARN\")\n",
    "\n",
    "        if not self.testid and not self._select_testcase():\n",
    "            raise Exception(\"æ— æ³•é€‰æ‹©æµ‹è¯•æ¡ˆä¾‹\")\n",
    "\n",
    "        requests.put(\n",
    "            f\"{self.url}/initialize/{self.testid}\",\n",
    "            json={\"start_time\": 0, \"warmup_period\": 0},\n",
    "            timeout=30,\n",
    "        )\n",
    "        requests.put(\n",
    "            f\"{self.url}/step/{self.testid}\", json={\"step\": 900}, timeout=10\n",
    "        )\n",
    "\n",
    "        resp = requests.post(\n",
    "            f\"{self.url}/advance/{self.testid}\", json={}, timeout=30\n",
    "        )\n",
    "        payload = resp.json().get('payload', {})\n",
    "        self.prev_action_norm = 0.0\n",
    "        return self._get_obs(payload)\n",
    "\n",
    "    def step(self, action_idx):\n",
    "        action = action_to_values(action_idx)\n",
    "\n",
    "        control = {\n",
    "            'fcu_oveFan_u': action['fan'],\n",
    "            'fcu_oveFan_activate': 1,\n",
    "            'fcu_oveTSup_u': action['supply_temp'],\n",
    "            'fcu_oveTSup_activate': 1,\n",
    "            'con_oveTSetHea_u': action['heat_setpoint'],\n",
    "            'con_oveTSetHea_activate': 1,\n",
    "            'con_oveTSetCoo_u': action['cool_setpoint'],\n",
    "            'con_oveTSetCoo_activate': 1,\n",
    "        }\n",
    "\n",
    "        resp = requests.post(\n",
    "            f\"{self.url}/advance/{self.testid}\", json=control, timeout=30\n",
    "        )\n",
    "        payload = resp.json().get('payload', {}) or {}\n",
    "\n",
    "        obs = self._get_obs(payload)\n",
    "        reward, reward_detail = self._calc_reward(obs)\n",
    "\n",
    "        sim_time = payload.get('time', 0)\n",
    "        done = sim_time >= STEPS_PER_EPISODE * 900\n",
    "\n",
    "        info = {\n",
    "            'sim_time': sim_time,\n",
    "            'room_temp': K2C(obs[0]),\n",
    "            'outdoor_temp': K2C(obs[1]),\n",
    "            'reward_detail': reward_detail,\n",
    "        }\n",
    "\n",
    "        self.prev_action_norm = action_idx / max(1, NUM_ACTIONS - 1)\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def _safe_get(self, payload, key, default):\n",
    "        v = payload.get(key, default)\n",
    "        if v is None:\n",
    "            return default\n",
    "        return v\n",
    "\n",
    "    def _get_obs(self, payload):\n",
    "        if not payload:\n",
    "            return np.zeros(self.obs_dim, dtype=np.float32)\n",
    "\n",
    "        sim_time = payload.get('time', 0)\n",
    "        hour = (sim_time % 86400) / 3600.0\n",
    "        day = (sim_time // 86400) % 365\n",
    "\n",
    "        room_temp = self._safe_get(payload, 'zon_reaTRooAir_y', 293.15)\n",
    "        outdoor_temp = self._safe_get(payload, 'zon_weaSta_reaWeaTDryBul_y', 283.15)\n",
    "        rel_hum = self._safe_get(payload, 'zon_weaSta_reaWeaRelHum_y', 0.5)\n",
    "        solar = self._safe_get(payload, 'zon_weaSta_reaWeaHGloHor_y', 0.0)\n",
    "        wind = self._safe_get(payload, 'zon_weaSta_reaWeaWinSpe_y', 0.0)\n",
    "        co2 = self._safe_get(payload, 'zon_reaCO2RooAir_y', 600.0)\n",
    "        p_heating = self._safe_get(payload, 'fcu_reaPHea_y', 0.0)\n",
    "        p_cooling = self._safe_get(payload, 'fcu_reaPCoo_y', 0.0)\n",
    "        p_fan = self._safe_get(payload, 'fcu_reaPFan_y', 0.0)\n",
    "\n",
    "        obs = np.array(\n",
    "            [\n",
    "                room_temp,\n",
    "                outdoor_temp,\n",
    "                rel_hum,\n",
    "                solar / 1000.0,  # kW/m2 é‡çº§\n",
    "                wind,\n",
    "                co2 / 1000.0,  # kppm é‡çº§\n",
    "                p_heating / 1000.0,  # kW\n",
    "                p_cooling / 1000.0,  # kW\n",
    "                p_fan / 1000.0,  # kW\n",
    "                np.sin(2 * np.pi * hour / 24),\n",
    "                np.cos(2 * np.pi * hour / 24),\n",
    "                self.prev_action_norm,\n",
    "            ],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "        return obs\n",
    "\n",
    "    def _calc_reward(self, obs):\n",
    "        room_temp_k = obs[0]\n",
    "        room_temp_c = K2C(room_temp_k)\n",
    "        p_h, p_c, p_f = obs[6], obs[7], obs[8]\n",
    "\n",
    "        # ã€ä¸ DQN ä¸€è‡´ã€‘Rewardï¼šèˆ’é€‚åŒºå†…ç»Ÿä¸€å¥–åŠ±ï¼ŒåŒºå¤–åŸºäºè·ç¦»è¾¹ç•Œçš„æƒ©ç½šï¼ˆè·ç¦»è¶Šå¤§æƒ©ç½šè¶Šå¤§ï¼‰\n",
    "        COMFORT_LOW, COMFORT_HIGH = 20.0, 24.0\n",
    "        if COMFORT_LOW <= room_temp_c <= COMFORT_HIGH:\n",
    "            comfort = 3.0\n",
    "        else:\n",
    "            if room_temp_c < COMFORT_LOW:\n",
    "                temp_dev_from_boundary = COMFORT_LOW - room_temp_c\n",
    "            else:  # room_temp_c > COMFORT_HIGH\n",
    "                temp_dev_from_boundary = room_temp_c - COMFORT_HIGH\n",
    "            comfort = -3.0 * (temp_dev_from_boundary ** 2)  # é™ä½æƒ©ç½šæ–œç‡ï¼Œä¾¿äºçˆ¬å¡\n",
    "        \n",
    "        # æç«¯æ¸©åº¦é¢å¤–ç¡¬æƒ©ç½šï¼ˆå‡å¼±ä»¥ä¾¿å¯æ¢å¤ï¼‰\n",
    "        if room_temp_c < 18.0 or room_temp_c > 26.0:\n",
    "            comfort -= 15.0\n",
    "\n",
    "        # èƒ½è€—æƒ©ç½šï¼šä¼˜å…ˆèˆ’é€‚ï¼Œæƒé‡ä¿æŒæ¸©å’Œ\n",
    "        if 20.0 <= room_temp_c <= 24.0:\n",
    "            energy = -0.15 * (p_h + p_c) - 0.03 * p_f\n",
    "        else:\n",
    "            energy = -0.05 * (p_h + p_c) - 0.01 * p_f\n",
    "        \n",
    "        smooth = -0.01 * abs(obs[-1] - self.prev_action_norm)\n",
    "\n",
    "        reward = comfort + energy + smooth\n",
    "        # å¥–åŠ±è£å‰ªï¼Œé¿å…æ¢¯åº¦è¢«æç«¯å€¼ä¸»å¯¼\n",
    "        reward = float(np.clip(reward, -50.0, 5.0))\n",
    "\n",
    "        detail = {\n",
    "            'comfort': comfort,\n",
    "            'energy': energy,\n",
    "            'smooth': smooth,\n",
    "            'room_temp_c': room_temp_c,\n",
    "            'in_comfort_zone': 20.0 <= room_temp_c <= 24.0,\n",
    "        }\n",
    "        return reward, detail\n",
    "\n",
    "    def stop(self):\n",
    "        if self.testid:\n",
    "            try:\n",
    "                requests.put(f\"{self.url}/stop/{self.testid}\", timeout=10)\n",
    "                self.testid = None\n",
    "            except Exception as e:\n",
    "                log(f\"åœæ­¢å¤±è´¥: {e}\", \"WARN\")\n",
    "\n",
    "# =====================================================================\n",
    "# PPO ç½‘ç»œ\n",
    "# =====================================================================\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, hidden=128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(state_dim, hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden, action_dim),\n",
    "        )\n",
    "\n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(state_dim, hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden, 1),\n",
    "        )\n",
    "\n",
    "        # æ­£äº¤åˆå§‹åŒ–ï¼šå‰å±‚ç”¨è¾ƒå¤§ gainï¼Œæœ€åä¸€å±‚å° gain ä¿å®ˆè¾“å‡º\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                gain = np.sqrt(2)\n",
    "                if m.out_features == action_dim or m.out_features == 1:\n",
    "                    gain = 0.01\n",
    "                nn.init.orthogonal_(m.weight, gain=gain)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def get_action(self, state, deterministic=False):\n",
    "        logits = self.actor(state)\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        dist = torch.distributions.Categorical(probs)\n",
    "\n",
    "        if deterministic:\n",
    "            action = probs.argmax(dim=-1)\n",
    "        else:\n",
    "            action = dist.sample()\n",
    "\n",
    "        return action, dist.log_prob(action), dist.entropy(), probs\n",
    "\n",
    "    def get_value(self, state):\n",
    "        return self.critic(state).squeeze(-1)\n",
    "\n",
    "    def evaluate_action(self, state, action):\n",
    "        logits = self.actor(state)\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        dist = torch.distributions.Categorical(probs)\n",
    "\n",
    "        log_prob = dist.log_prob(action)\n",
    "        entropy = dist.entropy()\n",
    "        value = self.critic(state).squeeze(-1)\n",
    "\n",
    "        return log_prob, entropy, value\n",
    "\n",
    "# =====================================================================\n",
    "# PPO æ™ºèƒ½ä½“\n",
    "# =====================================================================\n",
    "\n",
    "class PPOAgent:\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        self.model = ActorCritic(state_dim, action_dim)\n",
    "        # åˆ†åˆ«è®¾ç½®actorå’Œcriticçš„å­¦ä¹ ç‡\n",
    "        self.optimizer = optim.Adam([\n",
    "            {'params': self.model.actor.parameters(), 'lr': LEARNING_RATE_ACTOR},\n",
    "            {'params': self.model.critic.parameters(), 'lr': LEARNING_RATE_CRITIC}\n",
    "        ])\n",
    "\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "\n",
    "        log(f\"PPO Agent åˆå§‹åŒ–: {action_dim} actions\")\n",
    "        log(f\"  Actorå­¦ä¹ ç‡: {LEARNING_RATE_ACTOR}\")\n",
    "        log(f\"  Criticå­¦ä¹ ç‡: {LEARNING_RATE_CRITIC}\")\n",
    "        log(f\"  ç†µç³»æ•°: {ENTROPY_COEF}\")\n",
    "        log(f\"  PPO clip: {PPO_CLIP}\")\n",
    "\n",
    "    def select_action(self, state, deterministic=False):\n",
    "        with torch.no_grad():\n",
    "            state_t = torch.FloatTensor(state).unsqueeze(0)\n",
    "            action, log_prob, entropy, probs = self.model.get_action(\n",
    "                state_t, deterministic\n",
    "            )\n",
    "            value = self.model.get_value(state_t)\n",
    "            return action.item(), log_prob.item(), value.item(), probs[0].numpy()\n",
    "\n",
    "    def update(self, rollout):\n",
    "        states = torch.FloatTensor(np.array(rollout['states']))\n",
    "        actions = torch.LongTensor(rollout['actions'])\n",
    "        old_log_probs = torch.FloatTensor(rollout['log_probs'])\n",
    "        rewards = rollout['rewards']\n",
    "        dones = rollout['dones']\n",
    "        values = rollout['values']\n",
    "        last_value = rollout['last_value']\n",
    "\n",
    "        # è®¡ç®—GAEï¼Œæœ«æ­¥ä½¿ç”¨ bootstrap value\n",
    "        advantages = []\n",
    "        returns = []\n",
    "        gae = 0\n",
    "\n",
    "        for t in reversed(range(len(rewards))):\n",
    "            next_value = last_value if t == len(rewards) - 1 else values[t + 1]\n",
    "            delta = rewards[t] + GAMMA * next_value * (1 - dones[t]) - values[t]\n",
    "            gae = delta + GAMMA * GAE_LAMBDA * (1 - dones[t]) * gae\n",
    "            advantages.insert(0, gae)\n",
    "            returns.insert(0, gae + values[t])\n",
    "\n",
    "        advantages = torch.FloatTensor(advantages)\n",
    "        returns = torch.FloatTensor(returns)\n",
    "\n",
    "        advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n",
    "\n",
    "        total_loss = total_policy = total_value = total_entropy = 0.0\n",
    "        num_updates = 0\n",
    "        dataset_size = len(states)\n",
    "\n",
    "        for _ in range(PPO_EPOCHS):\n",
    "            indices = np.random.permutation(dataset_size)\n",
    "\n",
    "            for start in range(0, dataset_size, MINI_BATCH_SIZE):\n",
    "                end = min(start + MINI_BATCH_SIZE, dataset_size)\n",
    "                idx = indices[start:end]\n",
    "\n",
    "                new_log_probs, entropy, new_values = self.model.evaluate_action(\n",
    "                    states[idx], actions[idx]\n",
    "                )\n",
    "\n",
    "                ratio = torch.exp(new_log_probs - old_log_probs[idx])\n",
    "                surr1 = ratio * advantages[idx]\n",
    "                surr2 = torch.clamp(ratio, 1 - PPO_CLIP, 1 + PPO_CLIP) * advantages[idx]\n",
    "                policy_loss = -torch.min(surr1, surr2).mean()\n",
    "\n",
    "                value_loss = nn.functional.mse_loss(new_values, returns[idx])\n",
    "                entropy_loss = entropy.mean()\n",
    "\n",
    "                loss = policy_loss + VALUE_COEF * value_loss - ENTROPY_COEF * entropy_loss\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(self.model.parameters(), MAX_GRAD_NORM)\n",
    "                self.optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                total_policy += policy_loss.item()\n",
    "                total_value += value_loss.item()\n",
    "                total_entropy += entropy_loss.item()\n",
    "                num_updates += 1\n",
    "\n",
    "        return {\n",
    "            'loss': total_loss / num_updates,\n",
    "            'policy_loss': total_policy / num_updates,\n",
    "            'value_loss': total_value / num_updates,\n",
    "            'entropy': total_entropy / num_updates,\n",
    "        }\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "        log(f\"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {path}\")\n",
    "\n",
    "# =====================================================================\n",
    "# è®­ç»ƒç›‘æ§\n",
    "# =====================================================================\n",
    "\n",
    "class Monitor:\n",
    "    def __init__(self, save_dir=\"training_data\"):\n",
    "        self.save_dir = save_dir\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        self.train_rewards = []\n",
    "        self.train_temps = []\n",
    "        self.train_comfort_ratios = []  # èˆ’é€‚åŒºæ—¶é—´æ¯”ä¾‹\n",
    "        self.train_energy_consumption = []  # èƒ½è€—\n",
    "        self.eval_rewards = []\n",
    "        self.eval_episodes = []\n",
    "        self.entropies = []\n",
    "        \n",
    "        # è¯¦ç»†æ•°æ®è®°å½•\n",
    "        self.episode_data = []  # æ¯episodeçš„è¯¦ç»†æ•°æ®\n",
    "        \n",
    "        # å½“å‰episodeçš„è½¨è¿¹\n",
    "        self.last_actions = []\n",
    "        self.last_temps = []\n",
    "        self.last_outdoor = []\n",
    "        self.last_rewards = []\n",
    "        self.last_comfort_details = []  # èˆ’é€‚åº¦è¯¦æƒ…\n",
    "        self.last_energy_details = []  # èƒ½è€—è¯¦æƒ…\n",
    "        self.last_action_counts = Counter()\n",
    "        \n",
    "        # è®­ç»ƒå†å²ï¼ˆç”¨äºä¿å­˜ï¼‰\n",
    "        self.training_history = {\n",
    "            \"episodes\": [],\n",
    "            \"rewards\": [],\n",
    "            \"temps\": [],\n",
    "            \"comfort_ratios\": [],\n",
    "            \"energy_consumption\": [],\n",
    "            \"eval_episodes\": [],\n",
    "            \"eval_rewards\": [],\n",
    "        }\n",
    "\n",
    "    def log_episode_curves(self, actions, temps, outdoors, rewards, comfort_details=None, energy_details=None):\n",
    "        self.last_actions = actions\n",
    "        self.last_temps = temps\n",
    "        self.last_outdoor = outdoors\n",
    "        self.last_rewards = rewards\n",
    "        self.last_comfort_details = comfort_details or []\n",
    "        self.last_energy_details = energy_details or []\n",
    "        self.last_action_counts = Counter(actions)\n",
    "    \n",
    "    def save_episode_data(self, episode, actions, temps, outdoors, rewards, comfort_details, energy_details):\n",
    "        \"\"\"ä¿å­˜å•ä¸ªepisodeçš„è¯¦ç»†æ•°æ®\"\"\"\n",
    "        episode_data = {\n",
    "            \"episode\": episode,\n",
    "            \"steps\": len(actions),\n",
    "            \"actions\": actions,\n",
    "            \"temperatures\": temps,\n",
    "            \"outdoor_temps\": outdoors,\n",
    "            \"rewards\": rewards,\n",
    "            \"comfort_details\": comfort_details,\n",
    "            \"energy_details\": energy_details,\n",
    "            \"avg_temp\": float(np.mean(temps)) if temps else 0,\n",
    "            \"comfort_ratio\": float(np.mean([1 if 20 <= t <= 24 else 0 for t in temps])) if temps else 0,\n",
    "            \"total_energy\": float(np.sum(energy_details)) if energy_details else 0,\n",
    "        }\n",
    "        self.episode_data.append(episode_data)\n",
    "        \n",
    "        # ä¿å­˜åˆ°JSONæ–‡ä»¶\n",
    "        json_path = os.path.join(self.save_dir, f\"episode_{episode}.json\")\n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(episode_data, f, indent=2)\n",
    "    \n",
    "    def save_training_summary(self):\n",
    "        \"\"\"ä¿å­˜è®­ç»ƒæ€»ç»“\"\"\"\n",
    "        summary = {\n",
    "            \"total_episodes\": len(self.train_rewards),\n",
    "            \"training_history\": self.training_history,\n",
    "            \"final_stats\": {\n",
    "                \"avg_reward\": float(np.mean(self.train_rewards[-50:])) if len(self.train_rewards) >= 50 else float(np.mean(self.train_rewards)) if self.train_rewards else 0,\n",
    "                \"avg_temp\": float(np.mean(self.train_temps[-50:])) if len(self.train_temps) >= 50 else float(np.mean(self.train_temps)) if self.train_temps else 0,\n",
    "                \"avg_comfort_ratio\": float(np.mean(self.train_comfort_ratios[-50:])) if len(self.train_comfort_ratios) >= 50 else float(np.mean(self.train_comfort_ratios)) if self.train_comfort_ratios else 0,\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        summary_path = os.path.join(self.save_dir, \"training_summary.json\")\n",
    "        with open(summary_path, 'w') as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        \n",
    "        # ä¿å­˜CSVæ ¼å¼ï¼ˆä¾¿äºåˆ†æï¼‰\n",
    "        csv_path = os.path.join(self.save_dir, \"training_history.csv\")\n",
    "        with open(csv_path, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['Episode', 'Reward', 'AvgTemp', 'ComfortRatio', 'EnergyConsumption'])\n",
    "            for i in range(len(self.train_rewards)):\n",
    "                writer.writerow([\n",
    "                    i + 1,\n",
    "                    self.train_rewards[i],\n",
    "                    self.train_temps[i],\n",
    "                    self.train_comfort_ratios[i] if i < len(self.train_comfort_ratios) else 0,\n",
    "                    self.train_energy_consumption[i] if i < len(self.train_energy_consumption) else 0,\n",
    "                ])\n",
    "        \n",
    "        log(f\"ğŸ’¾ è®­ç»ƒæ•°æ®å·²ä¿å­˜åˆ° {self.save_dir}\")\n",
    "\n",
    "    def plot(self, save_path=None):\n",
    "        \"\"\"å¢å¼ºç‰ˆè®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–ï¼ˆä¸ DQN ä¸€è‡´ï¼‰\"\"\"\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "        # 1. è®­ç»ƒå¥–åŠ±\n",
    "        ax = axes[0, 0]\n",
    "        episodes = list(range(1, len(self.train_rewards) + 1))\n",
    "        ax.plot(episodes, self.train_rewards, 'b-', alpha=0.4, label='Raw')\n",
    "        if len(self.train_rewards) >= 10:\n",
    "            # MA(10): éœ€è¦10ä¸ªæ•°æ®ç‚¹ï¼Œä»ç¬¬10ä¸ªepisodeå¼€å§‹\n",
    "            ma = np.convolve(self.train_rewards, np.ones(10) / 10, mode='valid')\n",
    "            ma_episodes = list(range(10, len(self.train_rewards) + 1))  # å¯¹é½åˆ°æ•´æ•°episode\n",
    "            ax.plot(ma_episodes, ma, 'r-', linewidth=2, label='MA(10)')\n",
    "        ax.set_title('Training Reward', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Episode')\n",
    "        ax.set_ylabel('Reward')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # 2. å¹³å‡æ¸©åº¦\n",
    "        ax = axes[0, 1]\n",
    "        ax.plot(self.train_temps, 'g-', linewidth=1.5)\n",
    "        ax.axhspan(20, 24, alpha=0.2, color='green', label='Comfort Zone')\n",
    "        ax.axhline(22, color='r', linestyle='--', linewidth=1.5, label='Target 22Â°C')\n",
    "        ax.set_title('Average Temperature', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Episode')\n",
    "        ax.set_ylabel('Temperature (Â°C)')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # 3. èˆ’é€‚åŒºæ—¶é—´æ¯”ä¾‹\n",
    "        ax = axes[0, 2]\n",
    "        if self.train_comfort_ratios:\n",
    "            ax.plot(self.train_comfort_ratios, 'purple', linewidth=1.5)\n",
    "            ax.axhline(0.8, color='orange', linestyle='--', label='Target 80%')\n",
    "        ax.set_title('Comfort Zone Ratio', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Episode')\n",
    "        ax.set_ylabel('Ratio (0-1)')\n",
    "        ax.set_ylim(0, 1.05)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # 4. èƒ½è€—è¶‹åŠ¿\n",
    "        ax = axes[1, 0]\n",
    "        if self.train_energy_consumption:\n",
    "            ax.plot(self.train_energy_consumption, 'orange', linewidth=1.5)\n",
    "        ax.set_title('Energy Consumption', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Episode')\n",
    "        ax.set_ylabel('Total Energy (kW)')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # 5. è¯„ä¼°å¥–åŠ±\n",
    "        ax = axes[1, 1]\n",
    "        if self.eval_rewards:\n",
    "            ax.plot(self.eval_episodes, self.eval_rewards, 'ro-', markersize=6, linewidth=2)\n",
    "        ax.set_title('Evaluation Reward', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Episode')\n",
    "        ax.set_ylabel('Eval Reward')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # 6. æ¸©åº¦åˆ†å¸ƒï¼ˆæœ€è¿‘50ä¸ªepisodeï¼‰\n",
    "        ax = axes[1, 2]\n",
    "        if len(self.train_temps) >= 50:\n",
    "            recent_temps = self.train_temps[-50:]\n",
    "            ax.hist(recent_temps, bins=20, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "            ax.axvline(22, color='r', linestyle='--', linewidth=2, label='Target 22Â°C')\n",
    "            ax.axvspan(20, 24, alpha=0.2, color='green', label='Comfort Zone')\n",
    "        ax.set_title('Temperature Distribution (Last 50 Episodes)', fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('Temperature (Â°C)')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "            log(f\"ğŸ“Š å›¾è¡¨å·²ä¿å­˜: {save_path}\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_episode_curves(self, episode, save_dir=None):\n",
    "        if not self.last_actions:\n",
    "            return\n",
    "        steps = range(1, len(self.last_actions) + 1)\n",
    "\n",
    "        decoded = [action_to_values(a) for a in self.last_actions]\n",
    "        fan_seq = [d['fan'] for d in decoded]\n",
    "        supply_seq = [K2C(d['supply_temp']) for d in decoded]\n",
    "        heat_seq = [K2C(d['heat_setpoint']) for d in decoded]\n",
    "        cool_seq = [K2C(d['cool_setpoint']) for d in decoded]\n",
    "\n",
    "        # å¢å¼ºç‰ˆï¼š4è¡Œ3åˆ—ï¼Œæ·»åŠ èˆ’é€‚åº¦å’Œèƒ½è€—ï¼ˆä¸ DQN ä¸€è‡´ï¼‰\n",
    "        fig, axes = plt.subplots(4, 3, figsize=(20, 16))\n",
    "\n",
    "        ax = axes[0, 0]\n",
    "        ax.plot(steps, self.last_temps, label='Room Temp', linewidth=2, color='blue')\n",
    "        ax.plot(steps, self.last_outdoor, label='Outdoor Temp', alpha=0.6, color='gray', linestyle='--')\n",
    "        ax.axhspan(20, 24, alpha=0.15, color='green', label='Comfort Zone 20-24Â°C')\n",
    "        ax.axhline(22, color='r', linestyle='--', linewidth=1.5, label='Target 22Â°C')\n",
    "        ax.set_title(f'Episode {episode} | Temperature Profile', fontsize=11, fontweight='bold')\n",
    "        ax.set_xlabel('Step (15min)')\n",
    "        ax.set_ylabel('Temperature (Â°C)')\n",
    "        ax.legend(loc='best')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        ax = axes[0, 1]\n",
    "        ax.plot(steps, self.last_rewards, 'tab:orange', linewidth=1.5)\n",
    "        ax.set_title('Step Rewards', fontsize=11, fontweight='bold')\n",
    "        ax.set_xlabel('Step')\n",
    "        ax.set_ylabel('Reward')\n",
    "        ax.axhline(0, color='gray', linestyle='--', alpha=0.5)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # èˆ’é€‚åº¦è¯¦æƒ…\n",
    "        ax = axes[0, 2]\n",
    "        if self.last_comfort_details:\n",
    "            ax.plot(steps, self.last_comfort_details, 'green', linewidth=1.5, label='Comfort Reward')\n",
    "            ax.axhline(0, color='gray', linestyle='--', alpha=0.5)\n",
    "            # æ ‡è®°èˆ’é€‚åŒº\n",
    "            comfort_zones = [1 if 20 <= t <= 24 else 0 for t in self.last_temps]\n",
    "            ax2 = ax.twinx()\n",
    "            ax2.fill_between(steps, 0, comfort_zones, alpha=0.2, color='green', label='In Comfort Zone')\n",
    "            ax2.set_ylabel('Comfort Zone (0/1)', color='green')\n",
    "            ax2.set_ylim(-0.1, 1.1)\n",
    "        ax.set_title('Comfort Reward Details', fontsize=11, fontweight='bold')\n",
    "        ax.set_xlabel('Step')\n",
    "        ax.set_ylabel('Comfort Reward')\n",
    "        ax.legend(loc='upper left')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        ax = axes[1, 0]\n",
    "        ax.scatter(steps, self.last_actions, s=15, alpha=0.6, color='steelblue')\n",
    "        ax.set_title('Action Index per Step', fontsize=11, fontweight='bold')\n",
    "        ax.set_xlabel('Step')\n",
    "        ax.set_ylabel('Action Index (0-23)')\n",
    "        ax.set_ylim(-1, max(self.last_actions) + 2)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        ax = axes[1, 1]\n",
    "        items = sorted(self.last_action_counts.items(), key=lambda x: x[0])\n",
    "        if items:\n",
    "            labels, counts = zip(*items)\n",
    "            ax.bar(labels, counts, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "        ax.set_title('Action Usage Histogram', fontsize=11, fontweight='bold')\n",
    "        ax.set_xlabel('Action Index')\n",
    "        ax.set_ylabel('Usage Count')\n",
    "        ax.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "        ax = axes[2, 0]\n",
    "        ax.plot(steps, supply_seq, label='Supply Temp', linewidth=1.5, color='red')\n",
    "        ax.plot(steps, heat_seq, label='Heat Setpoint', linewidth=1.5, color='orange')\n",
    "        ax.plot(steps, cool_seq, label='Cool Setpoint', linewidth=1.5, color='blue')\n",
    "        ax.set_title('Supply Temperature & Setpoints', fontsize=11, fontweight='bold')\n",
    "        ax.set_xlabel('Step')\n",
    "        ax.set_ylabel('Temperature (Â°C)')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        ax = axes[2, 1]\n",
    "        ax.plot(steps, fan_seq, label='Fan u', color='tab:purple', linewidth=1.5)\n",
    "        ax.set_title('Fan Control', fontsize=11, fontweight='bold')\n",
    "        ax.set_xlabel('Step')\n",
    "        ax.set_ylabel('0-1')\n",
    "        ax.set_ylim(0, 1.05)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # èƒ½è€—è¯¦æƒ…\n",
    "        ax = axes[2, 2]\n",
    "        if self.last_energy_details:\n",
    "            ax.plot(steps, self.last_energy_details, 'orange', linewidth=1.5, label='Energy Cost')\n",
    "            ax.set_title('Energy Consumption per Step', fontsize=11, fontweight='bold')\n",
    "            ax.set_xlabel('Step')\n",
    "            ax.set_ylabel('Energy (kW)')\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "\n",
    "        # æ¸©åº¦åˆ†å¸ƒç›´æ–¹å›¾\n",
    "        ax = axes[3, 0]\n",
    "        if self.last_temps:\n",
    "            ax.hist(self.last_temps, bins=20, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "            ax.axvline(22, color='r', linestyle='--', linewidth=2, label='Target 22Â°C')\n",
    "            ax.axvspan(20, 24, alpha=0.2, color='green', label='Comfort Zone')\n",
    "            ax.set_title('Temperature Distribution', fontsize=11, fontweight='bold')\n",
    "            ax.set_xlabel('Temperature (Â°C)')\n",
    "            ax.set_ylabel('Frequency')\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "        # å¥–åŠ±åˆ†è§£ï¼ˆèˆ’é€‚åº¦ vs èƒ½è€—ï¼‰\n",
    "        ax = axes[3, 1]\n",
    "        if self.last_comfort_details and self.last_energy_details:\n",
    "            # ç´¯ç§¯å¥–åŠ±\n",
    "            cum_comfort = np.cumsum(self.last_comfort_details)\n",
    "            cum_energy = np.cumsum([-e for e in self.last_energy_details])  # è´Ÿå€¼è¡¨ç¤ºæƒ©ç½š\n",
    "            ax.plot(steps, cum_comfort, 'g-', linewidth=2, label='Cumulative Comfort')\n",
    "            ax.plot(steps, cum_energy, 'orange', linewidth=2, label='Cumulative Energy (neg)')\n",
    "            ax.axhline(0, color='gray', linestyle='--', alpha=0.5)\n",
    "            ax.set_title('Cumulative Reward Components', fontsize=11, fontweight='bold')\n",
    "            ax.set_xlabel('Step')\n",
    "            ax.set_ylabel('Cumulative Reward')\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "\n",
    "        # ç»Ÿè®¡ä¿¡æ¯\n",
    "        ax = axes[3, 2]\n",
    "        ax.axis('off')\n",
    "        avg_temp = np.mean(self.last_temps) if self.last_temps else 0\n",
    "        comfort_ratio = np.mean([1 if 20 <= t <= 24 else 0 for t in self.last_temps]) if self.last_temps else 0\n",
    "        total_energy = sum(self.last_energy_details) if self.last_energy_details else 0\n",
    "        total_reward = sum(self.last_rewards) if self.last_rewards else 0\n",
    "        avg_comfort_reward = np.mean(self.last_comfort_details) if self.last_comfort_details else 0\n",
    "        \n",
    "        stats_text = f\"\"\"Episode {episode} Statistics\n",
    "{'='*50}\n",
    "Total Reward: {total_reward:.2f}\n",
    "Avg Temperature: {avg_temp:.2f}Â°C\n",
    "Comfort Zone Ratio: {comfort_ratio*100:.1f}%\n",
    "Total Energy: {total_energy:.2f} kW\n",
    "Avg Comfort Reward: {avg_comfort_reward:.2f}\n",
    "Steps: {len(self.last_actions)}\n",
    "Unique Actions: {len(self.last_action_counts)}\n",
    "\"\"\"\n",
    "        ax.text(0.1, 0.5, stats_text, fontsize=10, family='monospace',\n",
    "                verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        if save_dir:\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            fig.savefig(os.path.join(save_dir, f\"ppo_curves_ep{episode}.png\"), dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "# =====================================================================\n",
    "# è®­ç»ƒå‡½æ•°\n",
    "# =====================================================================\n",
    "\n",
    "def train():\n",
    "    print(\"=\" * 70, flush=True)\n",
    "    print(\"ğŸš€ BOPTEST PPO è®­ç»ƒ (å¼ºåŒ–ç‰ˆ)\", flush=True)\n",
    "    print(\"=\" * 70, flush=True)\n",
    "\n",
    "    # æ£€æŸ¥è¿æ¥\n",
    "    log(\"æ£€æŸ¥BOPTESTè¿æ¥...\")\n",
    "    try:\n",
    "        resp = requests.get(f\"{BOPTEST_URL}/testcases\", timeout=10)\n",
    "        log(\"âœ… è¿æ¥æˆåŠŸ!\")\n",
    "    except Exception as e:\n",
    "        log(f\"âŒ è¿æ¥å¤±è´¥: {e}\", \"ERROR\")\n",
    "        log(f\"è¯·ç¡®è®¤BOPTEST_URLæ˜¯å¦æ­£ç¡®: {BOPTEST_URL}\", \"ERROR\")\n",
    "        return None, None\n",
    "\n",
    "    env = BOPTESTEnv()\n",
    "    agent = PPOAgent(state_dim=env.obs_dim, action_dim=env.action_dim)\n",
    "    os.makedirs(DATA_SAVE_DIR, exist_ok=True)\n",
    "    os.makedirs(PLOT_SAVE_DIR, exist_ok=True)\n",
    "    monitor = Monitor(save_dir=DATA_SAVE_DIR)\n",
    "\n",
    "    print(f\"\\né…ç½®:\", flush=True)\n",
    "    print(f\"  Episodes: {TOTAL_EPISODES}\", flush=True)\n",
    "    print(f\"  æ­¥æ•°/Episode: {STEPS_PER_EPISODE}\", flush=True)\n",
    "    print(f\"  åŠ¨ä½œç©ºé—´: {NUM_ACTIONS}\", flush=True)\n",
    "    print(f\"  ç†µç³»æ•°: {ENTROPY_COEF} (æ§åˆ¶æ¢ç´¢)\", flush=True)\n",
    "    print(\"=\" * 70, flush=True)\n",
    "\n",
    "    best_reward = float('-inf')\n",
    "\n",
    "    for episode in range(1, TOTAL_EPISODES + 1):\n",
    "        print(f\"\\n{'=' * 60}\", flush=True)\n",
    "        print(f\"ğŸ“Š Episode {episode}/{TOTAL_EPISODES}\", flush=True)\n",
    "        print(f\"{'=' * 60}\", flush=True)\n",
    "\n",
    "        rollout = {\n",
    "            'states': [],\n",
    "            'actions': [],\n",
    "            'rewards': [],\n",
    "            'dones': [],\n",
    "            'log_probs': [],\n",
    "            'values': [],\n",
    "            'last_value': 0.0,\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            state = env.reset()\n",
    "        except Exception as e:\n",
    "            log(f\"âŒ Resetå¤±è´¥: {e}\", \"ERROR\")\n",
    "            env.stop()\n",
    "            env.testid = None\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "\n",
    "        total_reward = 0\n",
    "        temps = []\n",
    "        action_counts = {}\n",
    "        actions_seq = []\n",
    "        rewards_seq = []\n",
    "        outdoor_seq = []\n",
    "        comfort_details = []  # æ”¶é›†èˆ’é€‚åº¦è¯¦æƒ…\n",
    "        energy_details = []  # æ”¶é›†èƒ½è€—è¯¦æƒ…\n",
    "\n",
    "        # é¢„çƒ­æ­¥éª¤ï¼šå›ºå®šé«˜é£+é«˜ä¾›é£+é«˜æš–è®¾+é«˜å†·è®¾ï¼Œå¸®åŠ©å¿«é€Ÿå‡æ¸©ï¼ˆä¸ DQN ä¿æŒä¸€è‡´ï¼‰\n",
    "        WARMUP_STEPS = 4\n",
    "        WARMUP_ACTION = 23  # Fan=0.9, TSup=23Â°C, Heat=23Â°C, Cool=28Â°C\n",
    "        for _ in range(WARMUP_STEPS):\n",
    "            # ä½¿ç”¨ WARMUP_ACTIONï¼Œä½†éœ€è¦è·å–å¯¹åº”çš„ log_prob å’Œ value\n",
    "            with torch.no_grad():\n",
    "                state_t = torch.FloatTensor(state).unsqueeze(0)\n",
    "                logits = agent.model.actor(state_t)\n",
    "                probs = torch.softmax(logits, dim=-1)\n",
    "                dist = torch.distributions.Categorical(probs)\n",
    "                log_prob = dist.log_prob(torch.tensor([WARMUP_ACTION]))\n",
    "                value = agent.model.critic(state_t).squeeze(-1)\n",
    "            \n",
    "            next_state, reward, done, info = env.step(WARMUP_ACTION)\n",
    "            \n",
    "            rollout['states'].append(state)\n",
    "            rollout['actions'].append(WARMUP_ACTION)\n",
    "            rollout['rewards'].append(reward)\n",
    "            rollout['dones'].append(float(done))\n",
    "            rollout['log_probs'].append(log_prob.item())\n",
    "            rollout['values'].append(value.item())\n",
    "            \n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            temps.append(info['room_temp'])\n",
    "            actions_seq.append(WARMUP_ACTION)\n",
    "            rewards_seq.append(reward)\n",
    "            outdoor_seq.append(info['outdoor_temp'])\n",
    "            action_counts[WARMUP_ACTION] = action_counts.get(WARMUP_ACTION, 0) + 1\n",
    "            # æ”¶é›†è¯¦ç»†ä¿¡æ¯\n",
    "            rd = info['reward_detail']\n",
    "            comfort_details.append(rd['comfort'])\n",
    "            energy_details.append(abs(rd['energy']))  # èƒ½è€—ç»å¯¹å€¼\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        for step in range(STEPS_PER_EPISODE):\n",
    "            action, log_prob, value, probs = agent.select_action(\n",
    "                state, deterministic=False\n",
    "            )\n",
    "\n",
    "            action_counts[action] = action_counts.get(action, 0) + 1\n",
    "\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "\n",
    "            rollout['states'].append(state)\n",
    "            rollout['actions'].append(action)\n",
    "            rollout['rewards'].append(reward)\n",
    "            rollout['dones'].append(float(done))\n",
    "            rollout['log_probs'].append(log_prob)\n",
    "            rollout['values'].append(value)\n",
    "\n",
    "            total_reward += reward\n",
    "            temps.append(info['room_temp'])\n",
    "            actions_seq.append(action)\n",
    "            rewards_seq.append(reward)\n",
    "            outdoor_seq.append(info['outdoor_temp'])\n",
    "            \n",
    "            # æ”¶é›†è¯¦ç»†ä¿¡æ¯\n",
    "            rd = info['reward_detail']\n",
    "            comfort_details.append(rd['comfort'])\n",
    "            energy_details.append(abs(rd['energy']))  # èƒ½è€—ç»å¯¹å€¼\n",
    "\n",
    "            if (step + 1) % 10 == 0:\n",
    "                top3_actions = np.argsort(probs)[-3:][::-1]\n",
    "                top3_str = \", \".join(\n",
    "                    [f\"A{a}:{probs[a]:.2f}\" for a in top3_actions]\n",
    "                )\n",
    "\n",
    "                print(\n",
    "                    f\"  Step {step+1:3d} | \"\n",
    "                    f\"å®¤æ¸©={info['room_temp']:5.1f}Â°C | \"\n",
    "                    f\"å®¤å¤–={info['outdoor_temp']:5.1f}Â°C | \"\n",
    "                    f\"R={reward:+6.2f} | \"\n",
    "                    f\"åŠ¨ä½œ={action:2d} | \"\n",
    "                    f\"{action_to_string(action)}\",\n",
    "                    flush=True,\n",
    "                )\n",
    "                print(f\"           Top3æ¦‚ç‡: [{top3_str}]\", flush=True)\n",
    "                rd = info['reward_detail']\n",
    "                print(\n",
    "                    f\"           ç»†åˆ†: comfort={rd['comfort']:+.2f}, energy={rd['energy']:+.2f}, smooth={rd['smooth']:+.2f}\",\n",
    "                    flush=True,\n",
    "                )\n",
    "\n",
    "            state = next_state\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        # bootstrap æœ€åä»·å€¼ï¼ˆè‹¥æœªè¶…æ—¶ä¸”éç»ˆæ­¢ï¼Œå¯ç”¨å½“å‰çŠ¶æ€ä»·å€¼ï¼‰\n",
    "        with torch.no_grad():\n",
    "            last_value = agent.model.get_value(\n",
    "                torch.FloatTensor(state).unsqueeze(0)\n",
    "            ).item()\n",
    "        rollout['last_value'] = last_value\n",
    "\n",
    "        loss_info = agent.update(rollout)\n",
    "\n",
    "        avg_temp = np.mean(temps) if temps else 0\n",
    "        comfort_ratio = np.mean([1 if 20 <= t <= 24 else 0 for t in temps]) if temps else 0\n",
    "        total_energy = np.sum(energy_details) if energy_details else 0\n",
    "        \n",
    "        monitor.train_rewards.append(total_reward)\n",
    "        monitor.train_temps.append(avg_temp)\n",
    "        monitor.train_comfort_ratios.append(comfort_ratio)\n",
    "        monitor.train_energy_consumption.append(total_energy)\n",
    "        monitor.entropies.append(loss_info['entropy'])\n",
    "        \n",
    "        # æ›´æ–°è®­ç»ƒå†å²\n",
    "        monitor.training_history[\"episodes\"].append(episode)\n",
    "        monitor.training_history[\"rewards\"].append(float(total_reward))\n",
    "        monitor.training_history[\"temps\"].append(float(avg_temp))\n",
    "        monitor.training_history[\"comfort_ratios\"].append(float(comfort_ratio))\n",
    "        monitor.training_history[\"energy_consumption\"].append(float(total_energy))\n",
    "        \n",
    "        # è®°å½•episodeæ›²çº¿\n",
    "        monitor.log_episode_curves(actions_seq, temps, outdoor_seq, rewards_seq, \n",
    "                                   comfort_details, energy_details)\n",
    "        \n",
    "        # ä¿å­˜episodeè¯¦ç»†æ•°æ®\n",
    "        monitor.save_episode_data(episode, actions_seq, temps, outdoor_seq, \n",
    "                                 rewards_seq, comfort_details, energy_details)\n",
    "\n",
    "        unique_actions = len(action_counts)\n",
    "        most_common = sorted(action_counts.items(), key=lambda x: -x[1])[:3]\n",
    "\n",
    "        print(f\"\\nâœ… Episode {episode} å®Œæˆ\", flush=True)\n",
    "        print(f\"   æ€»å¥–åŠ±: {total_reward:.1f}\", flush=True)\n",
    "        print(f\"   å¹³å‡å®¤æ¸©: {avg_temp:.1f}Â°C (ç›®æ ‡ 20-24Â°C)\", flush=True)\n",
    "        print(f\"   èˆ’é€‚åŒºæ—¶é—´æ¯”ä¾‹: {comfort_ratio*100:.1f}%\", flush=True)\n",
    "        print(f\"   æ€»èƒ½è€—: {total_energy:.2f} kW\", flush=True)\n",
    "        print(\n",
    "            f\"   Loss: {loss_info['loss']:.4f} | Entropy: {loss_info['entropy']:.4f}\",\n",
    "            flush=True,\n",
    "        )\n",
    "        print(f\"   ä½¿ç”¨äº† {unique_actions} ç§ä¸åŒåŠ¨ä½œ\", flush=True)\n",
    "        print(\n",
    "            f\"   æœ€å¸¸ç”¨åŠ¨ä½œ: {[(a, action_to_string(a), c) for a, c in most_common]}\",\n",
    "            flush=True,\n",
    "        )\n",
    "\n",
    "        env.stop()\n",
    "        \n",
    "        # æ¯10ä¸ªepisodeä¿å­˜ä¸€æ¬¡è®­ç»ƒæ€»ç»“ï¼ˆè½»é‡çº§ï¼‰\n",
    "        if episode % 10 == 0:\n",
    "            monitor.save_training_summary()\n",
    "\n",
    "        if episode % EVAL_FREQUENCY == 0:\n",
    "            print(f\"\\nğŸ” è¯„ä¼°ä¸­ (ç¡®å®šæ€§ç­–ç•¥)...\", flush=True)\n",
    "            eval_rewards = []\n",
    "\n",
    "            for _ in range(2):\n",
    "                state = env.reset()\n",
    "                ep_reward = 0\n",
    "                for _ in range(STEPS_PER_EPISODE):\n",
    "                    action, _, _, _ = agent.select_action(\n",
    "                        state, deterministic=True\n",
    "                    )\n",
    "                    state, reward, done, _ = env.step(action)\n",
    "                    ep_reward += reward\n",
    "                    if done:\n",
    "                        break\n",
    "                eval_rewards.append(ep_reward)\n",
    "                env.stop()\n",
    "\n",
    "            avg_eval = np.mean(eval_rewards) if eval_rewards else 0\n",
    "            monitor.eval_episodes.append(episode)\n",
    "            monitor.eval_rewards.append(avg_eval)\n",
    "\n",
    "            print(f\"ğŸ“Š è¯„ä¼°å¥–åŠ±: {avg_eval:.1f}\", flush=True)\n",
    "\n",
    "            if avg_eval > best_reward:\n",
    "                best_reward = avg_eval\n",
    "                agent.save(\"best_model.pth\")\n",
    "                log(f\"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ best_model.pth | eval={avg_eval:.2f}\")\n",
    "\n",
    "            # ä¿å­˜å¹¶æ˜¾ç¤ºè®­ç»ƒå›¾è¡¨\n",
    "            plot_path = os.path.join(PLOT_SAVE_DIR, f\"training_progress_ep{episode}.png\")\n",
    "            monitor.plot(save_path=plot_path)\n",
    "            monitor.plot_episode_curves(episode, PLOT_SAVE_DIR)\n",
    "            \n",
    "            # ä¿å­˜è®­ç»ƒæ€»ç»“\n",
    "            monitor.save_training_summary()\n",
    "            \n",
    "            print(\n",
    "                f\"\\n{'='*60}\",\n",
    "                flush=True,\n",
    "            )\n",
    "            print(\n",
    "                f\"Episode {episode}: è®­ç»ƒ={total_reward:.1f}, è¯„ä¼°={avg_eval:.1f}, Entropy={loss_info['entropy']:.3f}\",\n",
    "                flush=True,\n",
    "            )\n",
    "            print(\n",
    "                f\"{'='*60}\\n\",\n",
    "                flush=True,\n",
    "            )\n",
    "\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    # ä¿å­˜æœ€ç»ˆæ¨¡å‹\n",
    "    agent.save(\"final_model.pth\")\n",
    "    log(\"è®­ç»ƒç»“æŸï¼Œå·²ä¿å­˜ final_model.pth\")\n",
    "    \n",
    "    # ä¿å­˜æœ€ç»ˆè®­ç»ƒæ€»ç»“\n",
    "    monitor.save_training_summary()\n",
    "    \n",
    "    # ç”Ÿæˆæœ€ç»ˆå›¾è¡¨\n",
    "    final_plot_path = os.path.join(PLOT_SAVE_DIR, \"training_final.png\")\n",
    "    monitor.plot(save_path=final_plot_path)\n",
    "    monitor.plot_episode_curves(\"final\", PLOT_SAVE_DIR)\n",
    "    \n",
    "    log(f\"ğŸ“Š æ‰€æœ‰è®­ç»ƒæ•°æ®å·²ä¿å­˜åˆ°: {monitor.save_dir}\")\n",
    "    log(f\"ğŸ“ˆ æ‰€æœ‰å›¾è¡¨å·²ä¿å­˜åˆ°: {PLOT_SAVE_DIR}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70, flush=True)\n",
    "    print(\"ğŸ‰ è®­ç»ƒå®Œæˆ!\", flush=True)\n",
    "    print(f\"   æœ€ä½³è¯„ä¼°å¥–åŠ±: {best_reward:.1f}\", flush=True)\n",
    "    print(\"=\" * 70, flush=True)\n",
    "\n",
    "    return agent, monitor\n",
    "\n",
    "# =====================================================================\n",
    "# å¯åŠ¨æç¤º\n",
    "# =====================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ“Œ PPOè®­ç»ƒä»£ç å·²åŠ è½½ (å¼ºåŒ–ç‰ˆ)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nBOPTEST URL: {BOPTEST_URL}\")\n",
    "print(f\"åŠ¨ä½œç©ºé—´: {NUM_ACTIONS} ä¸ªåŠ¨ä½œ\")\n",
    "print(f\"ç†µç³»æ•°: {ENTROPY_COEF} (è¶Šå¤§æ¢ç´¢è¶Šå¤š)\")\n",
    "print(\"\\nè¿è¡Œ: train()\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c36ebe30-66e3-4ab2-b649-33bb5cf2a9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸš€ BOPTEST PPO è®­ç»ƒ (å¼ºåŒ–ç‰ˆ)\n",
      "======================================================================\n",
      "[15:04:28] INFO  | æ£€æŸ¥BOPTESTè¿æ¥...\n",
      "[15:04:28] INFO  | âœ… è¿æ¥æˆåŠŸ!\n",
      "[15:04:28] INFO  | PPO Agent åˆå§‹åŒ–: 24 actions\n",
      "[15:04:28] INFO  |   Actorå­¦ä¹ ç‡: 0.0001\n",
      "[15:04:28] INFO  |   Criticå­¦ä¹ ç‡: 0.0005\n",
      "[15:04:28] INFO  |   ç†µç³»æ•°: 0.05\n",
      "[15:04:28] INFO  |   PPO clip: 0.2\n",
      "\n",
      "é…ç½®:\n",
      "  Episodes: 500\n",
      "  æ­¥æ•°/Episode: 672\n",
      "  åŠ¨ä½œç©ºé—´: 24\n",
      "  ç†µç³»æ•°: 0.05 (æ§åˆ¶æ¢ç´¢)\n",
      "======================================================================\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Episode 1/500\n",
      "============================================================\n",
      "[15:04:28] DEBUG | å¯ç”¨æµ‹è¯•æ¡ˆä¾‹: [{'testcaseid': 'bestest_air'}, {'testcaseid': 'bestest_hydronic'}, {'testcaseid': 'bestest_hydronic_heat_pump'}, {'testcaseid': 'multizone_office_complex_air'}, {'testcaseid': 'multizone_office_simple_air'}, {'testcaseid': 'multizone_office_simple_hydronic'}, {'testcaseid': 'multizone_residential_hydronic'}, {'testcaseid': 'singlezone_commercial_hydronic'}, {'testcaseid': 'testcase2'}, {'testcaseid': 'testcase3'}, {'testcaseid': 'twozone_apartment_hydronic'}]\n",
      "[15:04:28] INFO  | é€‰æ‹©æµ‹è¯•æ¡ˆä¾‹: bestest_air\n",
      "[15:04:58] ERROR | âŒ é€‰æ‹©å¤±è´¥: HTTPConnectionPool(host='localhost', port=80): Read timed out. (read timeout=30)\n",
      "[15:04:58] ERROR | âŒ Resetå¤±è´¥: æ— æ³•é€‰æ‹©æµ‹è¯•æ¡ˆä¾‹\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š Episode 2/500\n",
      "============================================================\n",
      "[15:05:00] DEBUG | å¯ç”¨æµ‹è¯•æ¡ˆä¾‹: [{'testcaseid': 'bestest_air'}, {'testcaseid': 'bestest_hydronic'}, {'testcaseid': 'bestest_hydronic_heat_pump'}, {'testcaseid': 'multizone_office_complex_air'}, {'testcaseid': 'multizone_office_simple_air'}, {'testcaseid': 'multizone_office_simple_hydronic'}, {'testcaseid': 'multizone_residential_hydronic'}, {'testcaseid': 'singlezone_commercial_hydronic'}, {'testcaseid': 'testcase2'}, {'testcaseid': 'testcase3'}, {'testcaseid': 'twozone_apartment_hydronic'}]\n",
      "[15:05:00] INFO  | é€‰æ‹©æµ‹è¯•æ¡ˆä¾‹: bestest_air\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train()\n",
      "Cell \u001b[0;32mIn[3], line 681\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    670\u001b[0m rollout \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    671\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstates\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactions\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_value\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m    678\u001b[0m }\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 681\u001b[0m     state \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    683\u001b[0m     log(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâŒ Resetå¤±è´¥: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERROR\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 179\u001b[0m, in \u001b[0;36mBOPTESTEnv.reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    177\u001b[0m         log(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mè·å–æµ‹è¯•æ¡ˆä¾‹åˆ—è¡¨å¤±è´¥: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWARN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtestid \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_testcase():\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mæ— æ³•é€‰æ‹©æµ‹è¯•æ¡ˆä¾‹\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    182\u001b[0m requests\u001b[38;5;241m.\u001b[39mput(\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/initialize/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtestid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    184\u001b[0m     json\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_time\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarmup_period\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m},\n\u001b[1;32m    185\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,\n\u001b[1;32m    186\u001b[0m )\n",
      "Cell \u001b[0;32mIn[3], line 140\u001b[0m, in \u001b[0;36mBOPTESTEnv._select_testcase\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m log(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mé€‰æ‹©æµ‹è¯•æ¡ˆä¾‹: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTESTCASE_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     resp \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/testcases/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTESTCASE_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/select\u001b[39m\u001b[38;5;124m\"\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m\n\u001b[1;32m    142\u001b[0m     )\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m    144\u001b[0m         data \u001b[38;5;241m=\u001b[39m safe_json(resp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselect testcase\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, data\u001b[38;5;241m=\u001b[39mdata, json\u001b[38;5;241m=\u001b[39mjson, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    670\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[1;32m    671\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    672\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    673\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    674\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    675\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    676\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[1;32m    677\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    679\u001b[0m     )\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:791\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    792\u001b[0m     conn,\n\u001b[1;32m    793\u001b[0m     method,\n\u001b[1;32m    794\u001b[0m     url,\n\u001b[1;32m    795\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    796\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    797\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    798\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    799\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[1;32m    800\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[1;32m    801\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[1;32m    802\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[1;32m    804\u001b[0m )\n\u001b[1;32m    806\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    807\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/urllib3/connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/http/client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1380\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5bad71-6908-48c6-9939-8a6a4d44f8e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8540fe11-bd04-400e-b8a5-040d04917acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad99078b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
