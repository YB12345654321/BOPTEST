{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daf2f5a-acf8-44c3-a62d-b6361aa1c2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BOPTEST HVAC Q-Table åŸºçº¿ï¼ˆç¦»æ•£åŠ¨ä½œï¼Œä¸ PPO/DQN/A2C åŒé€»è¾‘ï¼‰\n",
    "- åŒæ ·çš„è§‚æµ‹/å¥–åŠ±/åŠ¨ä½œå®šä¹‰ï¼ˆ24 åŠ¨ä½œï¼‰\n",
    "- é‡‡ç”¨ç®€å•çš„ç‰¹å¾ç¦»æ•£åŒ– + Q è¡¨ï¼Œepsilon-greedy\n",
    "- é€‚åˆä½œä¸ºå¯¹ç…§åŸºçº¿ï¼Œæ€§èƒ½æœ‰é™ä½†å¯è·‘é€šæµç¨‹\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =====================================================================\n",
    "# é…ç½®å‚æ•°\n",
    "# =====================================================================\n",
    "BOPTEST_URL = os.getenv(\"BOPTEST_URL\", \"http://localhost\")\n",
    "TESTCASE_NAME = \"bestest_air\"\n",
    "\n",
    "TOTAL_EPISODES = 500  # ä¸DQN/PPO/A2Cä¸€è‡´\n",
    "STEPS_PER_EPISODE = 96  # 1 day (96 steps = 1 day, 15min per step)ï¼Œä¸DQN/PPO/A2Cä¸€è‡´\n",
    "EVAL_FREQUENCY = 20  # ä¸DQN/PPOä¸€è‡´\n",
    "PLOT_SAVE_DIR = \"training_output\"\n",
    "\n",
    "# Q-learning è¶…å‚æ•°ï¼ˆä¼˜åŒ–ï¼šæé«˜å­¦ä¹ ç‡ï¼ŒåŠ å¿«æ”¶æ•›ï¼‰\n",
    "GAMMA = 0.99\n",
    "ALPHA = 0.15          # å­¦ä¹ ç‡ï¼ˆæé«˜ä»¥åŠ å¿«å­¦ä¹ ï¼‰\n",
    "EPS_START = 1.0\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY_STEPS = 20_000  # å¢åŠ è¡°å‡æ­¥æ•°ï¼Œä¿æŒæ›´é•¿æ—¶é—´æ¢ç´¢\n",
    "\n",
    "# åŠ¨ä½œç©ºé—´ï¼ˆä¸DQN/PPO/A2Cå®Œå…¨ä¸€è‡´ï¼Œç¡®ä¿å¯å¯¹æ¯”æ€§ï¼‰\n",
    "# 3 (fan) x 2 (supply) x 2 (heat) x 2 (cool) = 24 actions\n",
    "FAN_LEVELS = [0.3, 0.6, 0.9]\n",
    "SUPPLY_TEMP_LEVELS = [288.15, 296.15]  # ~15Â°C / 23Â°C\n",
    "HEAT_SETPOINT_LEVELS = [294.15, 296.15]  # 21Â°C / 23Â°C\n",
    "COOL_SETPOINT_LEVELS = [299.15, 301.15]  # 26Â°C / 28Â°C\n",
    "\n",
    "NUM_ACTIONS = (\n",
    "    len(FAN_LEVELS)\n",
    "    * len(SUPPLY_TEMP_LEVELS)\n",
    "    * len(HEAT_SETPOINT_LEVELS)\n",
    "    * len(COOL_SETPOINT_LEVELS)\n",
    ")\n",
    "\n",
    "# è§‚æµ‹ç¦»æ•£åŒ–æ¡¶ï¼ˆç²—ç³™åˆ†ç®±ï¼Œç¡®ä¿è¡¨è§„æ¨¡å¯æ§ï¼‰\n",
    "# æ¸©åº¦ï¼ˆå®¤æ¸©ã€å¤–æ¸©ï¼‰æŒ‰ 2Â°C åˆ†ç®±ï¼›æ¹¿åº¦æŒ‰ 0.1ï¼›åŠŸç‡æŒ‰ 0.5kWï¼›æ—¶é—´åˆ† 6 æ¡£ï¼ˆ4h ä¸€æ¡£ï¼‰\n",
    "BUCKETS = {\n",
    "    \"room_temp\": np.arange(10, 35, 2),       # æ‘„æ°\n",
    "    \"out_temp\": np.arange(-10, 40, 2),\n",
    "    \"rel_hum\": np.arange(0.0, 1.05, 0.1),\n",
    "    \"p_heating\": np.arange(0.0, 10.5, 0.5),  # kW\n",
    "    \"p_cooling\": np.arange(0.0, 10.5, 0.5),\n",
    "    \"p_fan\": np.arange(0.0, 5.5, 0.5),\n",
    "    \"time_bin\": np.arange(0, 24, 4),         # å°æ—¶åˆ†ç®±\n",
    "}\n",
    "\n",
    "# =====================================================================\n",
    "# å·¥å…·å‡½æ•°\n",
    "# =====================================================================\n",
    "\n",
    "def log(msg, level=\"INFO\"):\n",
    "    ts = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(f\"[{ts}] {level:5s} | {msg}\", flush=True)\n",
    "\n",
    "\n",
    "def safe_json(resp, ctx=\"\"):\n",
    "    try:\n",
    "        return resp.json()\n",
    "    except Exception as e:\n",
    "        log(\n",
    "            f\"JSON è§£æå¤±è´¥({ctx}): {type(e).__name__}: {e}. status={resp.status_code}, text={resp.text[:200]}\",\n",
    "            \"ERROR\",\n",
    "        )\n",
    "        return None\n",
    "\n",
    "\n",
    "def K2C(k):\n",
    "    return k - 273.15\n",
    "\n",
    "\n",
    "def action_to_values(action_idx):\n",
    "    cool_idx = action_idx % len(COOL_SETPOINT_LEVELS)\n",
    "    remaining = action_idx // len(COOL_SETPOINT_LEVELS)\n",
    "    heat_idx = remaining % len(HEAT_SETPOINT_LEVELS)\n",
    "    remaining //= len(HEAT_SETPOINT_LEVELS)\n",
    "    supply_idx = remaining % len(SUPPLY_TEMP_LEVELS)\n",
    "    fan_idx = remaining // len(SUPPLY_TEMP_LEVELS)\n",
    "\n",
    "    v = {\n",
    "        \"fan\": FAN_LEVELS[fan_idx],\n",
    "        \"supply_temp\": SUPPLY_TEMP_LEVELS[supply_idx],\n",
    "        \"heat_setpoint\": HEAT_SETPOINT_LEVELS[heat_idx],\n",
    "        \"cool_setpoint\": COOL_SETPOINT_LEVELS[cool_idx],\n",
    "    }\n",
    "\n",
    "    if v[\"cool_setpoint\"] <= v[\"heat_setpoint\"] + 1.5:\n",
    "        v[\"cool_setpoint\"] = v[\"heat_setpoint\"] + 1.5\n",
    "\n",
    "    v[\"fan\"] = float(np.clip(v[\"fan\"], 0.0, 1.0))\n",
    "    v[\"supply_temp\"] = float(np.clip(v[\"supply_temp\"], 285.15, 313.15))\n",
    "    v[\"heat_setpoint\"] = float(np.clip(v[\"heat_setpoint\"], 278.15, 308.15))\n",
    "    v[\"cool_setpoint\"] = float(np.clip(v[\"cool_setpoint\"], 278.15, 308.15))\n",
    "    return v\n",
    "\n",
    "\n",
    "def action_to_string(action_idx):\n",
    "    \"\"\"å°†åŠ¨ä½œç´¢å¼•è½¬æ¢ä¸ºå¯è¯»å­—ç¬¦ä¸²ï¼ˆä¸DQN/PPO/A2Cä¸€è‡´ï¼‰\"\"\"\n",
    "    v = action_to_values(action_idx)\n",
    "    return (\n",
    "        f\"Fan={v['fan']:.1f}|ä¾›é£={K2C(v['supply_temp']):.0f}Â°C|\"\n",
    "        f\"çƒ­è®¾={K2C(v['heat_setpoint']):.1f}Â°C|å†·è®¾={K2C(v['cool_setpoint']):.1f}Â°C\"\n",
    "    )\n",
    "\n",
    "\n",
    "def discretize(obs):\n",
    "    room_c = K2C(obs[0])\n",
    "    out_c = K2C(obs[1])\n",
    "    rel_h = obs[2]\n",
    "    p_h, p_c, p_f = obs[6], obs[7], obs[8]\n",
    "    # é€šè¿‡ sin/cos è¿˜åŸå°æ—¶è§’åº¦ï¼ˆè¿‘ä¼¼ï¼‰ï¼Œè¿™é‡Œç”¨åæ­£åˆ‡è¿‘ä¼¼å°æ—¶æ•°\n",
    "    sin_t, cos_t = obs[9], obs[10]\n",
    "    hour = (np.degrees(np.arctan2(sin_t, cos_t)) % 360) / 15  # 0-24\n",
    "\n",
    "    def bucket(val, edges):\n",
    "        return int(np.digitize([val], edges)[0])\n",
    "\n",
    "    return (\n",
    "        bucket(room_c, BUCKETS[\"room_temp\"]),\n",
    "        bucket(out_c, BUCKETS[\"out_temp\"]),\n",
    "        bucket(rel_h, BUCKETS[\"rel_hum\"]),\n",
    "        bucket(p_h, BUCKETS[\"p_heating\"]),\n",
    "        bucket(p_c, BUCKETS[\"p_cooling\"]),\n",
    "        bucket(p_f, BUCKETS[\"p_fan\"]),\n",
    "        bucket(hour, BUCKETS[\"time_bin\"]),\n",
    "    )\n",
    "\n",
    "# =====================================================================\n",
    "# ç¯å¢ƒï¼ˆä¸å…¶ä»–ç®—æ³•ä¿æŒä¸€è‡´ï¼‰\n",
    "# =====================================================================\n",
    "\n",
    "class BOPTESTEnv:\n",
    "    def __init__(self):\n",
    "        self.url = BOPTEST_URL\n",
    "        self.testid = None\n",
    "        self.obs_dim = 12\n",
    "        self.action_dim = NUM_ACTIONS\n",
    "        self.prev_action_norm = 0.0\n",
    "\n",
    "    def _select_testcase(self):\n",
    "        log(f\"é€‰æ‹©æµ‹è¯•æ¡ˆä¾‹: {TESTCASE_NAME}\")\n",
    "        try:\n",
    "            resp = requests.post(\n",
    "                f\"{self.url}/testcases/{TESTCASE_NAME}/select\", timeout=30\n",
    "            )\n",
    "            if resp.status_code == 200:\n",
    "                data = safe_json(resp, \"select testcase\")\n",
    "                if data:\n",
    "                    self.testid = data.get(\"testid\")\n",
    "                    if self.testid:\n",
    "                        log(f\"âœ… Test ID: {self.testid}\")\n",
    "                        time.sleep(3)\n",
    "                        return True\n",
    "                    else:\n",
    "                        log(\"âŒ æœªè¿”å› testid\", \"ERROR\")\n",
    "            else:\n",
    "                log(\n",
    "                    f\"âŒ é€‰æ‹©å¤±è´¥ï¼ŒçŠ¶æ€ç ={resp.status_code}, å“åº”={resp.text[:200]}\",\n",
    "                    \"ERROR\",\n",
    "                )\n",
    "        except Exception as e:\n",
    "            log(f\"âŒ é€‰æ‹©å¤±è´¥: {e}\", \"ERROR\")\n",
    "        return False\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"é‡ç½®ç¯å¢ƒï¼ˆä¼˜åŒ–ï¼šåªåœ¨ç¬¬ä¸€æ¬¡resetæ—¶é€‰æ‹©testcaseï¼Œä¹‹åå¤ç”¨ï¼‰\"\"\"\n",
    "        # åªåœ¨ç¬¬ä¸€æ¬¡resetæ—¶é€‰æ‹©æµ‹è¯•æ¡ˆä¾‹ï¼Œä¹‹åå¤ç”¨åŒä¸€ä¸ªtestid\n",
    "        if not self.testid:\n",
    "            if not self._select_testcase():\n",
    "                raise Exception(\"æ— æ³•é€‰æ‹©æµ‹è¯•æ¡ˆä¾‹\")\n",
    "\n",
    "        requests.put(\n",
    "            f\"{self.url}/initialize/{self.testid}\",\n",
    "            json={\"start_time\": 0, \"warmup_period\": 0},\n",
    "            timeout=30,\n",
    "        )\n",
    "        requests.put(\n",
    "            f\"{self.url}/step/{self.testid}\", json={\"step\": 900}, timeout=10\n",
    "        )\n",
    "\n",
    "        resp = requests.post(\n",
    "            f\"{self.url}/advance/{self.testid}\", json={}, timeout=30\n",
    "        )\n",
    "        payload = resp.json().get(\"payload\", {})\n",
    "        self.prev_action_norm = 0.0\n",
    "        return self._get_obs(payload)\n",
    "\n",
    "    def step(self, action_idx):\n",
    "        action = action_to_values(action_idx)\n",
    "        control = {\n",
    "            \"fcu_oveFan_u\": action[\"fan\"],\n",
    "            \"fcu_oveFan_activate\": 1,\n",
    "            \"fcu_oveTSup_u\": action[\"supply_temp\"],\n",
    "            \"fcu_oveTSup_activate\": 1,\n",
    "            \"con_oveTSetHea_u\": action[\"heat_setpoint\"],\n",
    "            \"con_oveTSetHea_activate\": 1,\n",
    "            \"con_oveTSetCoo_u\": action[\"cool_setpoint\"],\n",
    "            \"con_oveTSetCoo_activate\": 1,\n",
    "        }\n",
    "\n",
    "        resp = requests.post(\n",
    "            f\"{self.url}/advance/{self.testid}\", json=control, timeout=30\n",
    "        )\n",
    "        payload = resp.json().get(\"payload\", {}) or {}\n",
    "\n",
    "        obs = self._get_obs(payload)\n",
    "        reward, reward_detail = self._calc_reward(obs)\n",
    "\n",
    "        sim_time = payload.get(\"time\", 0)\n",
    "        done = sim_time >= STEPS_PER_EPISODE * 900\n",
    "\n",
    "        info = {\n",
    "            \"sim_time\": sim_time,\n",
    "            \"room_temp\": K2C(obs[0]),\n",
    "            \"outdoor_temp\": K2C(obs[1]),\n",
    "            \"reward_detail\": reward_detail,\n",
    "        }\n",
    "        self.prev_action_norm = action_idx / max(1, NUM_ACTIONS - 1)\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def _safe_get(self, payload, key, default):\n",
    "        v = payload.get(key, default)\n",
    "        if v is None:\n",
    "            return default\n",
    "        return v\n",
    "\n",
    "    def _get_obs(self, payload):\n",
    "        if not payload:\n",
    "            return np.zeros(self.obs_dim, dtype=np.float32)\n",
    "\n",
    "        sim_time = payload.get(\"time\", 0)\n",
    "        hour = (sim_time % 86400) / 3600.0\n",
    "\n",
    "        room_temp = self._safe_get(payload, \"zon_reaTRooAir_y\", 293.15)\n",
    "        outdoor_temp = self._safe_get(payload, \"zon_weaSta_reaWeaTDryBul_y\", 283.15)\n",
    "        rel_hum = self._safe_get(payload, \"zon_weaSta_reaWeaRelHum_y\", 0.5)\n",
    "        solar = self._safe_get(payload, \"zon_weaSta_reaWeaHGloHor_y\", 0.0)\n",
    "        wind = self._safe_get(payload, \"zon_weaSta_reaWeaWinSpe_y\", 0.0)\n",
    "        co2 = self._safe_get(payload, \"zon_reaCO2RooAir_y\", 600.0)\n",
    "        p_heating = self._safe_get(payload, \"fcu_reaPHea_y\", 0.0)\n",
    "        p_cooling = self._safe_get(payload, \"fcu_reaPCoo_y\", 0.0)\n",
    "        p_fan = self._safe_get(payload, \"fcu_reaPFan_y\", 0.0)\n",
    "\n",
    "        obs = np.array(\n",
    "            [\n",
    "                room_temp,\n",
    "                outdoor_temp,\n",
    "                rel_hum,\n",
    "                solar / 1000.0,\n",
    "                wind,\n",
    "                co2 / 1000.0,\n",
    "                p_heating / 1000.0,\n",
    "                p_cooling / 1000.0,\n",
    "                p_fan / 1000.0,\n",
    "                np.sin(2 * np.pi * hour / 24),\n",
    "                np.cos(2 * np.pi * hour / 24),\n",
    "                self.prev_action_norm,\n",
    "            ],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        return obs\n",
    "\n",
    "    def _calc_reward(self, obs):\n",
    "        room_temp_c = K2C(obs[0])\n",
    "        p_h, p_c, p_f = obs[6], obs[7], obs[8]\n",
    "\n",
    "        # ã€æ–°è®¾è®¡ã€‘Rewardï¼šèˆ’é€‚åŒºå†…ç»Ÿä¸€å¥–åŠ±ï¼Œèˆ’é€‚åŒºå¤–æŒ‰è·ç¦»è¾¹ç•ŒäºŒæ¬¡æƒ©ç½šï¼ˆä¸DQNä¸€è‡´ï¼‰\n",
    "        COMFORT_LOW, COMFORT_HIGH = 20.0, 24.0\n",
    "        \n",
    "        if COMFORT_LOW <= room_temp_c <= COMFORT_HIGH:\n",
    "            # èˆ’é€‚åŒºå†…ï¼šç»Ÿä¸€å¥–åŠ±ï¼ˆæ‰€æœ‰èˆ’é€‚åŒºå†…çš„æ¸©åº¦rewardä¸€æ ·ï¼‰\n",
    "            comfort = 5.0\n",
    "        else:\n",
    "            # èˆ’é€‚åŒºå¤–ï¼šè·ç¦»è¾¹ç•Œè¶Šè¿œï¼Œpenaltyè¶Šå¤§ï¼ˆäºŒæ¬¡å¢é•¿ï¼‰\n",
    "            if room_temp_c < COMFORT_LOW:\n",
    "                # ä½äº20Â°Cï¼šå’Œ20Â°Cæ¯”å·®è·\n",
    "                distance_from_boundary = COMFORT_LOW - room_temp_c\n",
    "            else:  # room_temp_c > COMFORT_HIGH\n",
    "                # é«˜äº24Â°Cï¼šå’Œ24Â°Cæ¯”å·®è·\n",
    "                distance_from_boundary = room_temp_c - COMFORT_HIGH\n",
    "            # å·®è·è¶Šå¤§æ‰£çš„è¶Šå¤šï¼špenalty = è·ç¦»Â²\n",
    "            # ä¾‹å¦‚ï¼šè·ç¦»1Â°Cæ‰£1ï¼Œè·ç¦»2Â°Cæ‰£4ï¼Œè·ç¦»3Â°Cæ‰£9\n",
    "            comfort = -(distance_from_boundary ** 2)\n",
    "\n",
    "        # èƒ½è€—æƒ©ç½šï¼šå¤§å¹…é™ä½æƒé‡ï¼Œä¼˜å…ˆä¿è¯èˆ’é€‚åº¦\n",
    "        # èˆ’é€‚åŒºå†…æ‰è€ƒè™‘èŠ‚èƒ½ï¼ŒåŒºé—´å¤–å‡ ä¹ä¸æƒ©ç½šèƒ½è€—\n",
    "        if 20.0 <= room_temp_c <= 24.0:\n",
    "            energy = -0.08 * (p_h + p_c) - 0.015 * p_f  # é™ä½èƒ½è€—æƒ©ç½š\n",
    "        else:\n",
    "            energy = -0.02 * (p_h + p_c) - 0.005 * p_f  # åŒºé—´å¤–å‡ ä¹ä¸æƒ©ç½š\n",
    "        \n",
    "        # åŠ¨ä½œå¹³æ»‘ï¼šé™ä½æƒé‡ï¼Œé¿å…è¿‡åº¦å¹³æ»‘\n",
    "        smooth = -0.005 * abs(obs[-1] - self.prev_action_norm)\n",
    "\n",
    "        reward = comfort + energy + smooth\n",
    "        # å¥–åŠ±è£å‰ªèŒƒå›´æ‰©å¤§ï¼Œå…è®¸æ›´é«˜çš„æ­£å¥–åŠ±\n",
    "        reward = float(np.clip(reward, -50.0, 10.0))\n",
    "\n",
    "        detail = {\n",
    "            \"comfort\": comfort,\n",
    "            \"energy\": energy,\n",
    "            \"smooth\": smooth,\n",
    "            \"room_temp_c\": room_temp_c,\n",
    "            \"in_comfort_zone\": 20.0 <= room_temp_c <= 24.0,\n",
    "        }\n",
    "        return reward, detail\n",
    "\n",
    "    def stop(self):\n",
    "        if self.testid:\n",
    "            try:\n",
    "                requests.put(f\"{self.url}/stop/{self.testid}\", timeout=10)\n",
    "                log(f\"âœ… ç¯å¢ƒå·²åœæ­¢ (testid: {self.testid})\")\n",
    "            except Exception as e:\n",
    "                log(f\"åœæ­¢å¤±è´¥: {e}\", \"WARN\")\n",
    "            finally:\n",
    "                self.testid = None  # æ¸…ç©º testidï¼Œä¸‹æ¬¡ reset æ—¶ä¼šé‡æ–°è·å–\n",
    "\n",
    "# =====================================================================\n",
    "# Q-Table Agent\n",
    "# =====================================================================\n",
    "\n",
    "class QTableAgent:\n",
    "    def __init__(self, n_actions):\n",
    "        self.n_actions = n_actions\n",
    "        self.table = {}\n",
    "\n",
    "    def _get_state_key(self, disc_state):\n",
    "        return tuple(disc_state)\n",
    "\n",
    "    def act(self, disc_state, eps):\n",
    "        key = self._get_state_key(disc_state)\n",
    "        if np.random.rand() < eps or key not in self.table:\n",
    "            return np.random.randint(self.n_actions)\n",
    "        return int(np.argmax(self.table[key]))\n",
    "\n",
    "    def update(self, disc_state, action, reward, disc_next, done, alpha, gamma):\n",
    "        key = self._get_state_key(disc_state)\n",
    "        next_key = self._get_state_key(disc_next)\n",
    "        if key not in self.table:\n",
    "            self.table[key] = np.zeros(self.n_actions, dtype=np.float32)\n",
    "        if next_key not in self.table:\n",
    "            self.table[next_key] = np.zeros(self.n_actions, dtype=np.float32)\n",
    "\n",
    "        q_sa = self.table[key][action]\n",
    "        q_next = 0.0 if done else np.max(self.table[next_key])\n",
    "        target = reward + gamma * q_next\n",
    "        self.table[key][action] = (1 - alpha) * q_sa + alpha * target\n",
    "\n",
    "# =====================================================================\n",
    "# ç›‘æ§ä¸å¯è§†åŒ–\n",
    "# =====================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Monitor:\n",
    "    def __init__(self):\n",
    "        self.train_rewards = []\n",
    "        self.train_temps = []\n",
    "        self.eval_rewards = []\n",
    "        self.eval_episodes = []\n",
    "        # è½¨è¿¹ç¼“å­˜ï¼šç”¨äºæŒ‰ episode å‡ºå›¾\n",
    "        self.last_actions = []\n",
    "        self.last_temps = []\n",
    "        self.last_outdoor = []\n",
    "        self.last_rewards = []\n",
    "        self.last_action_counts = Counter()\n",
    "\n",
    "    def log_episode_curves(self, actions, temps, outdoors, rewards):\n",
    "        self.last_actions = actions\n",
    "        self.last_temps = temps\n",
    "        self.last_outdoor = outdoors\n",
    "        self.last_rewards = rewards\n",
    "        self.last_action_counts = Counter(actions)\n",
    "\n",
    "    def plot(self):\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "\n",
    "        ax = axes[0]\n",
    "        ax.plot(self.train_rewards, 'b-', alpha=0.6)\n",
    "        if len(self.train_rewards) >= 5:\n",
    "            ma = np.convolve(self.train_rewards, np.ones(5) / 5, mode='valid')\n",
    "            ax.plot(range(4, len(self.train_rewards)), ma, 'r-', linewidth=2)\n",
    "        ax.set_title('Train Reward')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        ax = axes[1]\n",
    "        ax.plot(self.train_temps, 'g-')\n",
    "        ax.axhspan(20, 24, alpha=0.1, color='green')\n",
    "        ax.axhline(22, color='r', linestyle='--')\n",
    "        ax.set_title('Avg Temp (Â°C)')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        ax = axes[2]\n",
    "        if self.eval_rewards:\n",
    "            ax.plot(self.eval_episodes, self.eval_rewards, 'ro-')\n",
    "        ax.set_title('Eval Reward')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_episode_curves(self, episode, save_dir=None):\n",
    "        if not self.last_actions:\n",
    "            return\n",
    "        steps = range(1, len(self.last_actions) + 1)\n",
    "\n",
    "        # è§£ç åŠ¨ä½œä¸ºç‰©ç†æ§åˆ¶é‡\n",
    "        decoded = [action_to_values(a) for a in self.last_actions]\n",
    "        fan_seq = [d['fan'] for d in decoded]\n",
    "        supply_seq = [K2C(d['supply_temp']) for d in decoded]\n",
    "        heat_seq = [K2C(d['heat_setpoint']) for d in decoded]\n",
    "        cool_seq = [K2C(d['cool_setpoint']) for d in decoded]\n",
    "\n",
    "        fig, axes = plt.subplots(3, 2, figsize=(16, 12))\n",
    "\n",
    "        # æ¸©åº¦æ›²çº¿\n",
    "        ax = axes[0, 0]\n",
    "        ax.plot(steps, self.last_temps, label='Room')\n",
    "        ax.plot(steps, self.last_outdoor, label='Outdoor', alpha=0.5)\n",
    "        ax.axhspan(20, 24, alpha=0.1, color='green', label='Comfort 20-24')\n",
    "        ax.axhline(22, color='r', linestyle='--', label='Target 22')\n",
    "        ax.set_title(f'Episode {episode} | Temperature')\n",
    "        ax.set_xlabel('Step (15min)')\n",
    "        ax.set_ylabel('Â°C')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # å¥–åŠ±æ›²çº¿\n",
    "        ax = axes[0, 1]\n",
    "        ax.plot(steps, self.last_rewards, 'tab:orange')\n",
    "        ax.set_title('Step Rewards')\n",
    "        ax.set_xlabel('Step')\n",
    "        ax.set_ylabel('Reward')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # åŠ¨ä½œåºåˆ—\n",
    "        ax = axes[1, 0]\n",
    "        ax.scatter(steps, self.last_actions, s=12, alpha=0.7)\n",
    "        ax.set_title('Action Index per Step')\n",
    "        ax.set_xlabel('Step')\n",
    "        ax.set_ylabel('Action idx (0-23)')\n",
    "        ax.set_ylim(-1, max(self.last_actions) + 2)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # åŠ¨ä½œåˆ†å¸ƒ\n",
    "        ax = axes[1, 1]\n",
    "        items = sorted(self.last_action_counts.items(), key=lambda x: x[0])\n",
    "        if items:\n",
    "            labels, counts = zip(*items)\n",
    "            ax.bar(labels, counts, color='tab:blue')\n",
    "        ax.set_title('Action Histogram (Episode)')\n",
    "        ax.set_xlabel('Action idx')\n",
    "        ax.set_ylabel('Count')\n",
    "        ax.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "        # æ§åˆ¶æ›²çº¿ï¼ˆä¾›é£/è®¾å®š/é£æœºï¼‰\n",
    "        ax = axes[2, 0]\n",
    "        ax.plot(steps, supply_seq, label='TSupply (Â°C)')\n",
    "        ax.plot(steps, heat_seq, label='Heat set (Â°C)')\n",
    "        ax.plot(steps, cool_seq, label='Cool set (Â°C)')\n",
    "        ax.set_title('Supply / Setpoints')\n",
    "        ax.set_xlabel('Step')\n",
    "        ax.set_ylabel('Â°C')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        ax = axes[2, 1]\n",
    "        ax.plot(steps, fan_seq, label='Fan u', color='tab:purple')\n",
    "        ax.set_title('Fan Control')\n",
    "        ax.set_xlabel('Step')\n",
    "        ax.set_ylabel('0-1')\n",
    "        ax.set_ylim(0, 1.05)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        if save_dir:\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            fig.savefig(os.path.join(save_dir, f\"qtable_curves_ep{episode}.png\"), dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "# =====================================================================\n",
    "# è®­ç»ƒå¾ªç¯\n",
    "# =====================================================================\n",
    "\n",
    "def linear_eps(step):\n",
    "    return max(EPS_END, EPS_START - (EPS_START - EPS_END) * step / EPS_DECAY_STEPS)\n",
    "\n",
    "\n",
    "def train():\n",
    "    print(\"=\" * 70, flush=True)\n",
    "    print(\"ğŸš€ BOPTEST Q-Table è®­ç»ƒ (ä¸ PPO/DQN/A2C åŒé€»è¾‘)\", flush=True)\n",
    "    print(\"=\" * 70, flush=True)\n",
    "\n",
    "    env = BOPTESTEnv()\n",
    "    agent = QTableAgent(NUM_ACTIONS)\n",
    "    monitor = Monitor()\n",
    "\n",
    "    # è¿æ¥æµ‹è¯•\n",
    "    try:\n",
    "        resp = requests.get(f\"{BOPTEST_URL}/testcases\", timeout=10)\n",
    "        if resp.status_code == 200:\n",
    "            data = safe_json(resp, \"list testcases\")\n",
    "            log(f\"âœ… è¿æ¥æˆåŠŸ! å¯ç”¨æ¡ˆä¾‹: {list(data) if data else 'æœªçŸ¥'}\")\n",
    "        else:\n",
    "            log(f\"âŒ è¿æ¥å¤±è´¥: {resp.status_code}, text={resp.text[:200]}\", \"ERROR\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        log(f\"âŒ è¿æ¥å¤±è´¥: {e}\", \"ERROR\")\n",
    "        return None\n",
    "\n",
    "    best_eval = -1e9\n",
    "    global_step = 0\n",
    "\n",
    "    for episode in range(1, TOTAL_EPISODES + 1):\n",
    "        print(f\"\\n{'=' * 60}\", flush=True)\n",
    "        print(f\"ğŸ“Š Episode {episode}/{TOTAL_EPISODES}\", flush=True)\n",
    "        print(f\"{'=' * 60}\", flush=True)\n",
    "        \n",
    "        try:\n",
    "            state = env.reset()\n",
    "        except Exception as e:\n",
    "            log(f\"âŒ Resetå¤±è´¥: {e}\", \"ERROR\")\n",
    "            env.stop()\n",
    "            env.testid = None\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "\n",
    "        disc_state = discretize(state)\n",
    "        total_reward = 0.0\n",
    "        temps = []\n",
    "        actions_seq = []\n",
    "        rewards_seq = []\n",
    "        outdoor_seq = []\n",
    "\n",
    "        for step in range(STEPS_PER_EPISODE):\n",
    "            eps = linear_eps(global_step)\n",
    "            action = agent.act(disc_state, eps)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            disc_next = discretize(next_state)\n",
    "\n",
    "            agent.update(disc_state, action, reward, disc_next, done, ALPHA, GAMMA)\n",
    "\n",
    "            disc_state = disc_next\n",
    "            total_reward += reward\n",
    "            temps.append(info[\"room_temp\"])\n",
    "            actions_seq.append(action)\n",
    "            rewards_seq.append(reward)\n",
    "            outdoor_seq.append(info[\"outdoor_temp\"])\n",
    "            global_step += 1\n",
    "\n",
    "            # è¯¦ç»†æ‰“å°ï¼ˆæ¯ 10 æ­¥ï¼‰\n",
    "            if (step + 1) % 10 == 0:\n",
    "                # è·å–å½“å‰çŠ¶æ€çš„ Q å€¼\n",
    "                state_key = agent._get_state_key(disc_state)\n",
    "                if state_key in agent.table:\n",
    "                    q_vals = agent.table[state_key]\n",
    "                    top3_actions = np.argsort(q_vals)[-3:][::-1]\n",
    "                    top3_str = \", \".join([f\"A{a}:Q={q_vals[a]:.2f}\" for a in top3_actions])\n",
    "                else:\n",
    "                    top3_str = \"N/A (æ–°çŠ¶æ€)\"\n",
    "                \n",
    "                print(\n",
    "                    f\"  Step {step+1:3d} | \"\n",
    "                    f\"å®¤æ¸©={info['room_temp']:5.1f}Â°C | \"\n",
    "                    f\"å®¤å¤–={info['outdoor_temp']:5.1f}Â°C | \"\n",
    "                    f\"R={reward:+6.2f} | \"\n",
    "                    f\"åŠ¨ä½œ={action:2d} | \"\n",
    "                    f\"{action_to_string(action)}\",\n",
    "                    flush=True,\n",
    "                )\n",
    "                print(f\"           Top3 Qå€¼: [{top3_str}] | eps={eps:.3f}\", flush=True)\n",
    "                rd = info[\"reward_detail\"]\n",
    "                print(\n",
    "                    f\"           ç»†åˆ†: comfort={rd['comfort']:+.2f}, energy={rd['energy']:+.2f}, smooth={rd['smooth']:+.2f}\",\n",
    "                    flush=True,\n",
    "                )\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        avg_temp = np.mean(temps) if temps else 0\n",
    "        monitor.train_rewards.append(total_reward)\n",
    "        monitor.train_temps.append(avg_temp)\n",
    "        monitor.log_episode_curves(actions_seq, temps, outdoor_seq, rewards_seq)\n",
    "\n",
    "        # Episode æ€»ç»“\n",
    "        action_counts = Counter(actions_seq)\n",
    "        unique_actions = len(action_counts)\n",
    "        most_common = sorted(action_counts.items(), key=lambda x: -x[1])[:3]\n",
    "        \n",
    "        print(f\"\\nâœ… Episode {episode} å®Œæˆ\", flush=True)\n",
    "        print(f\"   æ€»å¥–åŠ±: {total_reward:.1f}\", flush=True)\n",
    "        print(f\"   å¹³å‡å®¤æ¸©: {avg_temp:.1f}Â°C (ç›®æ ‡ 20-24Â°C)\", flush=True)\n",
    "        print(f\"   Epsilon: {eps:.3f} | Q-states: {len(agent.table)}\", flush=True)\n",
    "        print(f\"   ä½¿ç”¨äº† {unique_actions} ç§ä¸åŒåŠ¨ä½œ\", flush=True)\n",
    "        print(\n",
    "            f\"   æœ€å¸¸ç”¨åŠ¨ä½œ: {[(a, action_to_string(a), c) for a, c in most_common]}\",\n",
    "            flush=True,\n",
    "        )\n",
    "\n",
    "        # ä¸å†æ¯ä¸ªepisodeéƒ½stopï¼Œåªåœ¨è®­ç»ƒç»“æŸæ—¶stopï¼ˆä¼˜åŒ–ï¼šé¿å…é‡å¤é€‰æ‹©testcaseï¼‰\n",
    "        # env.stop()  # æ³¨é‡Šæ‰ï¼Œåªåœ¨è®­ç»ƒç»“æŸæ—¶stop\n",
    "\n",
    "        # è¯„ä¼°ï¼ˆè´ªå¿ƒï¼‰\n",
    "        if episode % EVAL_FREQUENCY == 0:\n",
    "            eval_rewards = []\n",
    "            for _ in range(1):\n",
    "                s = env.reset()\n",
    "                ds = discretize(s)\n",
    "                ep_r = 0.0\n",
    "                for _ in range(STEPS_PER_EPISODE):\n",
    "                    a = agent.act(ds, eps=0.0)\n",
    "                    s, r, d, _ = env.step(a)\n",
    "                    ds = discretize(s)\n",
    "                    ep_r += r\n",
    "                    if d:\n",
    "                        break\n",
    "                eval_rewards.append(ep_r)\n",
    "                env.stop()\n",
    "            avg_eval = float(np.mean(eval_rewards)) if eval_rewards else 0\n",
    "            monitor.eval_episodes.append(episode)\n",
    "            monitor.eval_rewards.append(avg_eval)\n",
    "            print(f\"  ğŸ” Eval avg reward: {avg_eval:.2f}\", flush=True)\n",
    "            if avg_eval > best_eval:\n",
    "                best_eval = avg_eval\n",
    "                log(f\"ğŸ’¾ æ›´æ–°æœ€ä½³è¯„ä¼°æˆç»©: {best_eval:.2f}\")\n",
    "\n",
    "            monitor.plot()\n",
    "            monitor.plot_episode_curves(episode, PLOT_SAVE_DIR)\n",
    "\n",
    "    # è®­ç»ƒç»“æŸæ—¶æ‰stopç¯å¢ƒï¼ˆä¼˜åŒ–ï¼šé¿å…æ¯ä¸ªepisodeéƒ½é‡æ–°é€‰æ‹©testcaseï¼‰\n",
    "    env.stop()\n",
    "    \n",
    "    log(\"è®­ç»ƒç»“æŸ (Q-Table åŸºçº¿)\")\n",
    "    monitor.plot_episode_curves(\"final\", PLOT_SAVE_DIR)\n",
    "    return agent\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ“Œ Q-Table ä»£ç å·²åŠ è½½ (åŸºçº¿)\")\n",
    "print(\"åŠ¨ä½œç©ºé—´:\", NUM_ACTIONS)\n",
    "print(\"è¿è¡Œ: train()\")\n",
    "print(\"=\" * 60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dd2eb42-c0cf-4279-81ab-aa82b274d277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b2e2a0-fef9-4eea-9e1e-66b3816a1695",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
